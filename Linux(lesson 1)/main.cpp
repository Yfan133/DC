#include<iostream>
//Linux不以文件后缀区分，加后缀和颜色是为用户区分
//环境变量:就是一个变量,用于存储系统运行的环境参数
//操作指令:env set echo 查看环境变量 export 设置环境变量 unset 删除环境变量
//作用:
//1)通过修改环境变量的值,灵活的配置系统运行参数
//2)子进程会继承父进程的环境变量

///////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//Linux下以.为开头的文件默认不显示(隐藏文件)
//磁盘至少有两个分区：文件交换分区，文件系统分区（且交换分区只有一个，系统分区可以有多个）
//交换分区:作为交换内存使用，通常大小在16G以内，是内存的两倍，超过时相等即可
//文件系统分区：作为文件存储使用
//程序运行，运行信息占用的是内存，内存不够用了，把非活跃区内的数据放入磁盘上（文件交换分区）这样内存就有空间加载新的数据进行处理
//windows下磁盘分了多少分区，就可以有多少盘符，每个盘符都是一个大目录（给某个空间分配文件夹）
//linux下目录结构是惟一的，不会随着分区多少而改变（给某个目录分配空间）
//挂载是指：给某个目录分配一块磁盘空间，这个目录下的文件数据存储的时候就会存储到这个空间中

//目录操作
//绝对路径：以根目录作为起始表达的路径 例：./workspace/
//相对路径：是以某个路径
// .	表示目录自身
// ..	表示目录上一层
//mkdir -p 层层递进创建目录 rmdir -p 层层删除空目录(哪层为空就删除哪一层)
//rm -rf  删除目录及目录内所有文件
//批量删除以.h为后缀的文件 rm *.h
//cp -r  层层拷贝目录(文件)
//mv   (剪切)移动目录的位置

//文件操作
//touch  若文件不存在则创建，若存在则刷新文件的时间属性
//cat  分页显示文件内容
//head -n 显示文件前n行
//tail -n 显示文件尾n行
//echo  打印字符串，将数据写入标准输出(显示器设备文件)"sjk666" >> filename 把sjk666写入文件
//stat  查看文件状态
//>>或者>  重定向符号，进行数据流的重定向，文件重定向(echo "1" >> file将原本要写入标准输出的数据写入文件，改变数据的流向)
//>  先清空在输入数据
//>> 直接追加数据
//|  管道符连接两个命令（head -n 23 | tail -n 1）输出第12行

//打包指令
//压缩：将一个文件按压缩算法，将数据从多变少
/*
zip
gzip
bzip2
*/
//打包：将多个文件合并成一个文件
/*
tar  Linux下使用度很高的打包解包工具
-c打包 -x解包 -z打包同时进行gzip格式的压缩解压缩 -j打包同时进行bzip2格式的压缩解压缩 -v显示打包解包信息 -f用于指定tar包的名称，通常作为最后一个选项
tar -czvf new_name file	file				打包
tar -xvf  file(不加解包格式，则自动检测格式)	解包(默认解压到当前目录下)
*/
//单引号（会消除字符里特殊字符的特殊含义）双引号不会
//grep  从文件里查找匹配的行(文件里找函数)
//-v  反向匹配(不包含的行) -R  对某个目录进行层层寻找(每个文件都要查找)
//例：grep -i "sjk" ./op
//find  在目录中查找指定名称/大小/时间/类型的文件
//find ./ -name"*test*" (**为模糊匹配)  
//find ./ -type d 通过文件类型查找文件 -d -
//find ./ -size -10M  通过文件大小查找10M以内文件--+10M查找超过10M大小的文件
//find ./ -mmin -10  通过文件时间查找 --cmin,mmin,amin--分钟为单位
//
//		  -前面都有一个减号，为**以内
//tab  快捷键，文件名自动补全
//ctrl+c --中断当前操作

//shell的理解
//操作系统内核与用户之间的桥梁---命令行解释器
//shell会捕捉用户的标准输入，得到字符串，通过字符串判断用户想要干什么
//终端能执行命令就是因为运行了一个程序--shell--命令行解释器
//Windows下的shell就是操作界面(和操作内核沟通的桥梁)
//权限：限制用户权利的东西
//文件权限对用户：所有者-u，所属组-g，其他用户-o
//文件权限对操作：可读-r，可写-w，可执行-x
//在系统中权限的存储：使用二进制
// rw-rw-r--  --> 110 110 100  占用空间小，易操作
//也可以用八进制表示用户的权限110 110 100  --> 6 6 4

//文件访问权限指令
//umask -S(人性化显示) 查看或者设置文件的创建权限掩码
//umask 八进制掩码(显示的和权限八进制相反)，权限计算方法：777-八进制掩码
//创建好的文件进行权限修改
//chmod 777 hello.txt 直接使用八进制数进行修改
//chmod a-x hello.txt 对某个用户进行权限修改
//文件用户信息修改
//chown username filename 修改文件所有者(只能使用root修改)
//chgrp username filename 修改文件所属组
//文件权限沾滞位：特殊的权限位--主要用于设置目录沾滞位，其他用户在这个目录下能够创建文件，可以删除自己的文件，但不能删除别人的
//chmod +t filename

//vim 是一个命令行编辑器，不能使用鼠标(使用鼠标是无效的)
//vim具有多种操作模式：12种，常用的三种：插入模式，普通模式，底行模式
//普通模式：进行文本常见的操作-复制，剪切，粘贴，删除，撤销，返回，文本对齐，光标的快速移动
//底行模式：进行文本的保存退出，以及文本的匹配查找替换操作
//vim filename 若文件不存在创建，存在则打开，打开后处于普通模式
//:q!强制退出(不保存)
//i进入插入模式，a后移一个并插入，o新建一行并插入
//光标移动：hjkl上下左右，w/b按单词移动，ctrl+f/b上下翻页
//文本操作：yy/nyy-复制；p/P-粘贴,dd/ndd删除/剪切,x-删除光标所在字符,dw-删除单词
//u-撤销，ctrl+r-反撤销，gg=G--全文对齐

//编译器：gcc/g++
//gcc是C语言的编译器;g++是C++的编译器
/*编译过程											   -o 指定生成文件名称
预处理：将代码展开（引入头文件，宏替换，删除注释....） gcc-E filename 只进行预处理
编译：纠错，并将高级代码解释为汇编代码				   gcc-S		  只进行编译
汇编：将汇编代码解释成机器指令						   gcc-c		  只进行汇编
链接：将所有用到的机器指令文件打包到一起，生成可执行程序,不仅仅是我们的代码文件，还包括库文件(a.c文件引用了b.h中的函数)
*/

//链接库文件的时候有两种链接方式：动态链接与静态链接
//动态链接：链接动态库，在可执行程序中记录函数符号信息表，生成可执行程序比较小，但是运行时需要加载动态库，多个程序可以使用同一库，不会在内存中造成代码冗余
//静态链接：链接静态库，直接将使用的函数写入可执行程序中，生成的可执行程序比较大，运行时不需要额外加载库，多个程序使用了相同的静态库，运行时会造成内存的代码冗余
//gcc默认链接方式：动态链接
//gcc -g a.c b.h -o main
//调试器:gdb
//加载调试：gdb ./main
//开始调试：run  直接运行 start  逐步调试
//流程控制：n  下一步(逐过程)  s  下一步(逐语句)
//			l a.c:25  查看调试行附近代码  until a.c:25  直接运行到指定行
//			c 继续运行直到断点
//断点控制：break a.c:9  给第9行打断点  watch a  给变量打断点，当变量的值发生改变时停下来  d  删除断点
//内存操作：p a 查看变量数据 backtrace查看程序运行调用栈信息，程序一旦崩溃，查看调用栈可以快速定位崩溃位置--栈顶函数

//make/Makefile
//Makefile:普通的文本文件，用于记录
//$@:表示目标对象  main
//$^:表示所有依赖对象 a.c b.c
//$<:表示所有依赖对象中的第一个依赖对象
//wildcard/patsubst 关键字的使用
//make clean 清除make生成的对象
//伪对象的使用：
//.PHONY:目标对象名称
//伪对象的作用:不管对象是否最新，每次都要重新生成
//Makefile中
/*
.PHONY:clean
clean:
	rm -rf main.o main
*/

//git：项目版本管理工具
//1.git clone +链接  从远程仓库克隆到本地 
//2.git add ./*    添加本地文件
//3.git commit -m"删除了一个无效文件"  把文件保存到本地git
//4.git push origin master			   推送到git上

//进程概念：
//冯诺依曼体系结构---现代计算机的硬件体系结构
//现代计算机的硬件体系结构：五大硬件单元
//输入设备：采集数据的，如键盘
//存储器：进行中间数据缓冲， 
//运算器：进行数据处理  运算器+控制器=CPU中央处理器
//控制器：进行设备控制
//所有设备都是围绕存储器工作的：
//CPU不会直接从输入设备获取数据进行处理，而是先把数据放到存储器中，CPU从存储里中获取数据处理
//CPU不会直接将数据交给输出设备进行输出，而是把数据放入存储器，控制输出设备从存储器中获取数据并输出
//存储器就是运行内存，因为CPU从内存中读取数据速度是硬盘的十数倍。但内存中存储的数据在掉电之后就消失了，而硬盘掉电之后数据不会丢失，因此存储数据还是用硬盘。

//操作系统：是一个搞管理的软件（安装在计算机上的一个程序），管理计算机上的软硬件资源
//操作系统组成：内核(负责系统的核心功能-软硬件管理,内存管理,文件管理)+外部应用
//用户不能直接访问操作系统内核（危险性太高），为了控制风险，系统内核提供了一些访问的接口，每个接口完成的功能都是固定的---系统调用接口
//用户
//->系统调用接口：操作系统向用户提供访问内核的接口(shell指令,库函数封装了一系列系统调用接口)
//->操作系统
//->硬件驱动
//->（键盘鼠标等）


//什么是进程？为什么是这样？
//进程：进行中的程序，
//一个程序运行起来，有数据以及指令需要被CPU执行处理，数据会被加载到内存中，然后CPU从内存中获取数据
//操作系统中的进程都是同时运行的，但CPU只有一个，如何做到多个程序同时运行?
//CPU的分时机制：实现CPU轮询处理每一个运行中的程序，其实CPU只负责执行指令并处理数据（具体处理哪个程序CPU不管），而程序运行调度由操作系统进行管理，CPU处理运行的程序时，并不会一次性处理完毕，而是每个程序都只执行一个时间段(片)(该时间片由操作系统分配)，一个程序执行完一个时间片之后，下一个拿到时间片的程序开始执行
//调度：操作系统控制CPU该处理哪一个程序了

//操作系统的具体管理思路：操作系统将每个程序的运行信息保存下来,这样进行管理调度时就能知道这个程序上一次运行到了哪里
//对于操作系统来说，进程就是PCB，是一个程序运行的动态描述，通过PCB就能实现程序的运行的调度管理
//PCB内的描述信息：（Linux下的PCB就是一个struct task_struct结构体）
/*
内存指针：能够让操作系统调度程序运行的时候，知道程序对应的指令和数据在内存中的位置
上下文数据：CPU处理过的程序的指令和数据，正在处理中的指令和数据，即将要处理的指令和数据，操作系统进行调度让CPU处理程序上次未处理完成的数据，切换时保存正在执行的指令以及数据信息
程序计数器：也属于上下文数据，保存的就是指令位置，切换回来知道从哪里继续运行
标识符：能够让操作系统识别唯一的运行中的程序
IO信息,状态信息，优先级，记账信息
并发：CPU资源不够的情况下，采用CPU分时机制，CPU轮询处理数据（十个人过独木桥）
并行：多核CPU上，多个进程同时占据CPU进行数据处理（十个人并排过马路）
*/

//进程状态:每个进程PCB中都会描述一个运行的状态信息，通过状态信息，告诉操作系统这个进程现在应该干什么
//时间片：操作系统给每个程序分配的CPU处理时间，时间片运行完了就切换另一个程序
//进程状态：就绪，运行，阻塞(拿到时间片也不会运行)

//进程状态在Linux下分的更细
//(-R)运行状态-R：包含就绪以及运行，也就说正在运行的，以及拿到时间片就能运行的都称之为运行状态，操作系统读取PCB的状态信息之后就能调度运行
//休眠：暂时没有被CPU调度运行，让出CPU资源，休眠有唤醒条件，操作系统调度运行时会查看状态，满足唤醒条件则运行，不满足则切换下一个程序
//(-S)可中断休眠状态-S：可以被打断的休眠，满足运行条件或者被一些中断打断休眠之后进入运行状态
//(-D)不可中断休眠状态-D:只能通过满足运行条件之后，自然进入运行状态
//(-T)停止-T：与休眠不同(操作系统会查看进程是否满足唤醒条件，而停止只能手动唤醒)
//(-Z)僵尸状态-Z：一个进程已经退出，但是该进程的资源没有完全被释放，等待处理的一种状态
//僵尸进程：退出了但是资源没有完全释放的进程
/*
僵尸进程
危害：资源泄露（可能导致正常进程起不来）
产生原因：一个进程先于父进程退出，父进程没有关注子进程退出状态，导致子进程资源无法完全被释放，进入僵尸状态
解决：进程等待--一直关注子进程的状态

进程的创建：pid_t fork(void) --通过复制调用fork进程，创建一个新的进程
进程就是PCB，创建一个进程就是创建了一个PCB，上面复制调用了fork这个进程的PCB信息(内存指针，程序计数器，上下文数据)，新进程的运行代码和fork的一样，并且运行位置也一样
两个进程运行的程序相同：哪个是调用进程(父进程)，哪个是新建进程(子进程)？
在父进程中返回子进程的pid（pid_t pid=fork( )），大于0的；在子进程中返回0;但返回-1表示创建子进程失败

子进程从pid=fork()之后开始运行，因为父子进程运行代码的数据一样，所以无法直接分辨，只能通过返回值判断
对于父进程fork返回值>0  对于子进程返回值==0
fork创建子进程之后，父子进程谁先运行不一定，操作系统调度到谁谁就运行
为什么子进程会从fork()之后开始执行？
父子进程pcb一模一样，子进程pcb中的程序计数器(记录程序执行到哪里了，接下来该执行什么代码)记录的就是fork()这一行代码，因此从fork以下开始执行
getpid()获取调用进程的标识符pid
孤儿进程：父进程先于子进程退出，子进程就会成为孤儿进程
特性：让出终端，进入系统后台运行并且父进程成为1号进程，1号进程在centos7之前叫init进程，之后叫systemd，系统中父进程是1号进程的进程，通常以d结尾，表示它在后台运行
课后调研：守护进程、精灵进程
守护进程：特殊的孤儿进程，不但运行在后台，父进程成为1号进程，并且还与登录终端以及会话脱离关系(为了一个进程稳定不受影响的运行在后台)
*/
//查看进程信息
//ps -ef|head -1 && ps -ef|grep fork 显示fork进程ppid父进程,pid子进程
//ps -aux | grep test	aux详细显示，会显示进程当前状态
//前台进程：当前占据了终端的进程，

//环境变量：终端shell中进行系统运行环境配置的变量
//作用：1.可以使系统环境配置更加灵活(不像修改配置文件后还得加载配置问题)  2.可以通过环境变量向子程序传递数据
//操作指令：env -查看所有环境变量 echo--直接打印某个变量的内容  echo $PATH($表示后面的字符串是一个变量名称)export PATH=$PATH:. set-查看所有变量，不只是环境变量 export声明定义一个环境变量 unset-删除一个变量，也可以是环境变量
//export MYVAL=100;
//PATH：当前搜索程序运行路径
//运行一个程序的时候，如果没有指定程序路径，只有名称则shell会去PATH环境变量保存的路径中去找这个程序
//代码操作：char *getenv(char *key)
//在终端中运行的程序，父进程都是bash，也就是shell程序
//在终端中运行一个程序，其实是shell创建了一个进程，让这个进程去调度我们要运行的程序，这样做可以提高稳定性，创建出的进程崩溃了，shell还可以继续运行

//环境变量可以1.配置系统运行环境参数 2.向子程序传递一些数据(子进程会拥有与父进程相同的环境变量)
//环境变量一直都存在，可以在main函数参数列表中写出来，用于接收环境变量，一般嫌麻烦而省略了main函数的参数列表(不定参函数)
//main函数的三个参数：int main(int argc, char *argv[], char *env[])
//extern char **environ; 库中的全局变量，每个节点指向一个环境变量，但是使用时需要声明，告诉编译器有这个变量
//这种临时创建的环境变量，在重新打开终端之后就没有了，想持久配置就把信息加入到配置文件中
//课后调研：设置环境变量  setenv()/putenv()
/*
//////////////////////////////////////////////
通过代码查看(获取)环境变量
argc-->程序运行参数个数
argv[]-->用于执行程序中各个环境变量的一个字符串指针数组
./env -l -a  [./env]是第0个参数，[-l]是第一个参数，[-a]是第二个参数
env[]用于指向程序各个环境变量的一个字符串指针数组
1.
int main(int argc, char *argv[], char *env[])
{
	int i;
	for(i=0;env[i]!=NULL;i++)
		printf("environment:[%s]\n",env[i]);
}
2.
extern char **environ;
int i;
for(i=0;env[i]!=NULL;i++)
	printf("environment:[%s]\n",env[i]);
*/

//程序地址空间（进程地址空间）
//地址:内存地址---对内存以字节为存储单元的一个编号,32位内存大小4G(也就是0x0000 0000到0xffff ffff)
/*
内核空间
环境变量,运行参数
栈(往下生长)
...
...(共享区)
堆(往上生长)
未初始化全局
初始化全局
代码段
*/
//在父子进程fork()代码中父子进程代码共享，数据独有，但打印的父子进程地址相同，子进程内g_val=200，为什么呢？
//其实我们访问的地址都是虚拟地址--并非真正的内存地址，打印出来的都是虚拟地址，但其实在内存中地址不同
//若进程直接访问物理内存有哪些缺点：1.无法动态获知哪块内存是否被使用，程序编译时，编译器会给指令和数据进行地址编号，但如果该地址被使用程序就运行不起来了
//									2.如果该进程中有一个野指针，在直接访问物理内存时可能会改变其它地址的数据，造成其它程序崩溃
//									3.程序运行加载需要一块连续的内存空间，对物理内存利用率很低
//通过虚拟地址空间映射到物理内存空间，可以提高物理内存利用率,虚拟内存是连续的,每个进程都会拥有自己的一块连续的空间，但实际上在物理内存中是离散存储的
//如何通过虚拟空间地址找到物理地址空间？
//操作系统的内存管理方式:分段式(段号)，分页式(页表)，段页式
/*
分段式:
	通过段号在段表中查到初始内存地址,再用初始内存地址+段内偏移量找到对应的物理内存单元
分段式中每个段内数据的起始内存地址都是相同的，也就是说还是用了连续的物理内存空间无法离散式存储，未解决内存利用率低的问题
分页式:
通过页号查到初始内存地址,再用初始内存地址+页内偏移量找到对应的物理内存单元
优点:物理内存块大小跟虚拟内存页大小一样,物理内存块比较小,并且不要求同一进程的多个数据必须在同一个块内,因此分页式实现了数据在物理内存中的离散式存储,提高了内存利用率
页表会在进行内存访问时会进行内存访问权限查询(页表和)
十进制计算方法：虚拟地址/页表大小  ->找到对应物理地址+虚拟地址%页表大小
十六进制计算方法：虚拟地址高二十位是页号 ->找到对应物理地址+低二十位
页号占据的是高位，有2^20个页表所以占高20位，低20位为偏移量
32位操作系统 内存4G/4k == 页表项(页号)的个数 == 2^20  页表大小4096=4*1024=4k
段页式：将内存进行分段(代码段，数据段，堆，栈，环境变量等等)，在每个段内采用分页式管理
页表中有一个中断位--缺页中断，表示当前虚拟地址要找的数据是否在物理内存中(如果没在则会触发缺页中断)
一个进程的数据怎么会不在内存中呢？
内存管理：磁盘在分区的时候，至少有两个分区--交换分区和文件系统分区(用于文件数据存储)，内存不够时将内存中的某些不活跃的数据腾出来放到交换分区中，腾出空间给紧急的数据，等到使用该数据触发缺页中断时再交换回来/文件系统分区--用于文件数据存储
课后调研：内存置换算法:最久未使用（怎么快速定位最久未使用的数据）

进程控制：创建，终止，等待，程序替换
创建：如何创建一个进程？
	pid_t pid fork()；
	子进程复制父进程pcb，页表，虚拟地址空间都一样，所以刚开始父子进程除了个别数据(标识符pid)之外都是一样的，并且父子进程的数据指向同一块物理内存
	写时拷贝技术：子进程创建出来之后，与父进程映射访问同一物理内存，当某个物理内存中数据即将发生改变时(父进程数据发生改变或者子进程)重新为子进程开辟物理内存，拷贝数据过去。好处：防止给子进程创建空间，但子进程不用，降低了进程的创建效率，且造成内存冗余数据
	返回值：父进程pid>0，子进程pid==0，pid<0错误，通过返回值可以区分父子进程
	pid_t pid=vfork():
	也是创建子进程，但一个父进程使用vfork创建子进程之后，vfork的调用并不会立即返回(通常说会阻塞父进程)而是让子进程先运行，直到子进程退出，或者进行程序替换之后，父进程才能运行
	在程序运行中每调用一个函数，就会进行一次函数压栈---函数调用栈,vfork父子进程可能会造成栈混乱
	vfork的父子进程使用的同一块虚拟地址空间，也就是说使用了同一个栈，若父子进程同时运行则会造成调用栈混乱，因此让父进程等待子进程退出或者程序替换后，有了自己的地址空间(在原有的地址空间中子进程的调用就都出栈了)才开始运行
	pid_t vfork(void)  会造成死循环(vfork创建的子进程，不能在main函数中使用return退出，因为子进程使用return退出时释放了所有资源,父进程运行的时候资源是错误的)
	当父进程在main函数中调用fork函数创建子进程，fork运行完毕之后，父进程应该从调用fork函数的下一步开始执行
	fork父子进程各有各的栈，vfork父子进程共用同一块栈区
	总之vfork父子进程同一空间，fork父子进程不同空间
	问题：为什么vfork会造成无限循环？个人猜测：return释放资源后，父进程混乱
终止：如何退出一个进程？
	main函数中的return
	exit();可以在任何位置退出程序，库函数，exit退出进程时会刷新缓冲区，将缓冲区的数据写入标准输出
	_exit();					   系统调用接口，_exit退出进程直接释放资源，不会刷新缓冲区
	printf打印数据，实际上是把数据交给显示器，让显示器显示。先放入数据缓冲区，等积累到一定数量之后一次性输出(缓冲区满了)，这样做会提高程序运行效率。
	(\n)除了换行的作用之外，还有刷新缓冲区的作用，标准输出（使数据输出），\r回车
	fflush(stdout);刷新缓冲区
*/
/*
进程等待：为了获取退出子进程返回值，父进程等待子进程退出，释放退出子进程的所有资源，避免产生僵尸进程
僵尸进程产生原因：子进程先于父进程退出，而父进程没有关注子进程的退出信息，子进程为了保存退出返回值，而无法完全释放资源产生的
int wait(int *status);  阻塞接口，若没有子进程退出，则父进程阻塞，一直等待直到有子进程退出才会调用返回
int waitpid(int pid,int *status;int option);与wait不同，默认为非阻塞，父进程不会等待子进程退出，若没有子进程退出waitpid返回-1
	阻塞：为了完成一个功能，发起一个调用，若不具备完成功能的条件，则调用一直等待
	非阻塞：为了完成一个功能，发起一个调用，若不具备完成功能的条件，则调用立即报错并返回
	返回值：成功则返回处理过的子进程的pid，失败则返回-1(比如没有子进程退出)
正常退出：程序运行到return或者exit自然退出，
异常退出：程序在运行过程中崩溃而退出
子进程退出而父进程没有等待处理，都会变成僵尸进程
wait和waitpid的不同之处：
1.wait等待任意一个子进程退出后,就处理子进程并返回
  waitpid可以等待指定子进程，也可以等待任意一个子进程，通过第一个参数确定(第一个参数pid==-1则表示等待任意)
2.wait是阻塞接口（没有子进程退出则一直等待）
  waitpid可以默认成阻塞，也可设置为非阻塞，通过第三个参数确定(option==0表示默认阻塞，option==WNOHANG表示非阻塞)
进程等待返回值：成功返回退出，则子进程的pid，没有子进程退出返回0，错误返回-1
非阻塞操作通常循环处理，直到有子进程退出，处理并返回大于0的数

一个进程在运行中突然崩溃，这是由于一些异常引起的，进程自己怎么知道自己发生了异常呢？
由操作系统检测，操作系统检测到进程的低7位异常退出信号，则通知进程退出
怎么判断一个进程是否正常退出，取出低七位；用status & 0x7f ==0则正常退出
0x7f == 0111 1111
怎么取出返回值---低16位中的高8位？(status>>8) & 0xff
返回值只用8位(一个字节)保存，因此退出返回值不要大于255，即exit(255);最大了
if((status & 0x7f)==0)
	printf("退出返回值：%d\n",(status>>8) & 0xff);
用系统调用接口取出返回值：
if(WIFEXITED(status))
	printf("退出返回值：%d\n",WEXITSTATUS(status));
查看错误在哪里:#include<errno.h> #include<string.h>
int res=wait(NULL);
if(res<0){
	printf("%s\n",strerror(errno)); //errno是一个全局变量-保存上一次系统调用的错误编号
	perror("wait error");
}
core dump---核心转储
当一个程序崩溃之后，我们想要调试找到程序崩溃位置，以及崩溃原因，core dump会保存异常退出信息
gdb wait进入调试，输入core-file+拷贝文件名，就能定位出错位置了，bt查看堆栈信息
*/

/*
进程程序替换：替换一个进程，正在调度运行的程序
将当前进程的数据段和代码段进行替换，替换成为其他程序的数据和代码，并且更新堆栈数据
进程替换其实是修改了映射关系，把本来映射到内存中main的重新定位到test，这样也就修改了数据和代码
fork创建一个子进程，代码共享数据独有---父子进程做的事一样，但通常创建一个子进程是为了让子进程运行其他程序
execl("./a",NULL,NULL)；在当前目录下找a，不定参数为NULL
程序替换之后将会看到：1.进程标识符 pid 是没有变化的
					  2.
#include<unistd.h>
extern char**environ;
int execl("路径"，字符串，)  execl("ls的路径","ls","-l",NULL);不加路径则当前路径
int execlp					 execlp("ls","ls","-l",NULL);在PATH下寻找
int execle
l和v的区别：参数赋予方式不同
有没有p的区别：新的程序文件的名称是否需要带路径
有没有e的区别：是否自定义环境变量
int execv("路径"，指针数组)
int execvp
int execve
若程序替换失败则运行原本的代码
问题：程序替换之后，如果子程序执行时间比较长，而父进程很快就执行完毕了，会不会造成僵尸进程？
	不会进程替换之后，子进程不再是子进程了，而是一个新的进程
问题：为什么execlp("ls","ls","l",NULL);要写两次"ls"才能执行ls -l
Linux下一切皆文件，pwd在shell上是指令，其实就是一个可执行程序(文件)
32位操作系统内核：4G
1G	内核空间			 0x FFFF FFFF	
3G						 0x C000 0000
	命令行参数和环境变量
		栈
		.
		共享区
		.				 
		堆
		数据段
		代码段			 0x 0000 0000
*/
//minishell的工作
//1.能够从标准输入当中接收用户输入的命令
//2.创建子进程
//3.子进程进行程序替换
/////////////////////////////////////////////////////////////////////
//perror();非常好用的一个判断错误



/*
基础IO
1.C语言操作文件接口
	fopen(const char *Path，const char *mode);Path:文件地址+文件名称，Way读取方式
	FILE* fp=fopen("./Demo","r");
	fwrite(* ptr,size,nmemb,* stream);ptr:往文件里写的内容，size;写入的大小，nmemb：数量，stream：文件指针
	一般把size设置为1，则nmemb为字节大小,fwrite("aaa",1,3,fp);fwrite返回的是写成功的数量
	fread(* ptr,size,nmemb,* stream);ptr将读到的内容保存的位置
	fread(b, size, N, fp);从文件读取内容并保存到数组b，返回读的数量
	"linux_57" 这个字符串常量最后面有一个'\0'
	fseek(* stream,offset,whence);offset偏移量,whence:SEEK_SET:头部 SEEK_CUR:偏移到指定位置 SEEK_END:末尾
	调整文件指针偏移量
2.系统调用函数的操作文件接口 open,read,write,lseek,close
	open(* pathname,int flags,mode_t mode);		返回值：打开成功返回文件描述符，失败返回-1
	O_RDONLY	只读			八进制0		
	O_WRONLY	只写				  1
	O_RDWR		可读写				  2
	O_CREAT		不存在则创建文件	  100
	int fd = open("path",O_RDWR | O_CREAT,0664）可读写，没有创建，权限664(八进制)->对应二进制 110 110 100
	O_RDWR | O_CREAT
	00000000 00000000 00000000 00000010		八进制2	  可读可写
	00000000 00000000 00000000 01000010		八进制100 创建
	按位或(有1则为1)
	00000000 00000000 00000000 01000010
								^    ^
	这八个比特位表示不同的打开文件方式，当前是可读可写且创建
	read(fd,* buf,count);fd文件描述符，open的返回值,buf读到哪里去，count最大可以读多少个，返回写成功的大小
	lseek()
	close()

	int fd=open()		->文件描述符
	write(fd,"linux-57",8);
	lseek(fd,0,SEEK_SET);
	char buf[1024]={0};
	read(fd,buf,sizeof(buf)-1);	//buf最后面要留一个'\0'的位置
3.文件描述符  fd
	cd /proc/
	ll /proc/标识符/fd
	操作系统会给每个进程在磁盘中创建一个以进程号(pid:进程标识符)命名的文件夹，该文件下有一个fd文件夹，保存的是文件描述符
	新创建的进程会打开三个文件描述符，分别对应，标准输入(0)，标准输出(1)，标准错误(2)，不关闭前三个则打开其他（3），没有关闭会造成句柄泄露
	创建一个进程相当于创建了一个task_struct结构体，这个结构体里有叫files的结构体指针，指向叫files_struct的结构体，这个结构体内有数组fd_array保存着很多文件描述符（struct file*）（保存着文件原信息，文件大小，权限等等），数组fd_array[]的下标
	文件描述符是一个正整数，close(0);关闭了标准输入，再fp=open()打开文件则给fd分配0，按从零开始最小数分配
	
	FILE是typedef struct _IO_FILE，里面保存着读写缓冲区(C库中的东西)，最下面还有一个指针int _fileno，保存的就是文件描述符的数值，exit()退出时刷新缓冲区就是读缓冲区，操作的是文件流指针，而_exit()无法刷新是因为它是系统调用接口
	不同的文件流指针，在C库中会创建不同的struct _IO_FILE，
4.文件描述符和文件流指针的区别，文件流指针也就是FILE* fp中有一个指针int _fileno；保存的就是文件描述符的数值
	1)文件流指针是fopen函数返回的，是库函数维护的
	2)文件描述符是open函数返回的，是内核维护的
	C语言中FILE 在操作系统中其实是struct _IO_FILE 结构体：
	不同文件流指针会创建不同的IO结构体，保存了不同的文件描述符，文件流指针里保存着很多文件描述符
	c库维护的exit函数在退出时，会刷新缓冲区，而操作系统接口_exit函数不会刷新缓冲区
5.重定向接口
	>>和>
	重新让标准输出，由屏幕指向文件，相当于把指向文件描述符 0 的指针转为指向文件描述符 1
	dup2(int oldfd，int newfd)；newfd拷贝oldfd的值
	dup2(fd,1);关闭1号文件描述符，并拷贝fd的文件描述符，也就是把原本标准输出到屏幕的，重新输入到文件中
	修改fd相当于修改了本进程的文件描述符，进程最多打开1024-3个文件，其实那三个指向同一个设备文件/dev/pts/2

当打开一个文件时，系统会给程序分配一个文件描述符，如果使用完毕没有关闭文件，就会造成文件句柄泄露，
一个进程当中最大打开的文件数量是多少？
1.默认打开文件数量1024   其实真实不是1024，（3~1023）要减去默认的三个文件，0：标准输入，1：标准输出，2：标准错误 实际打开文件1021
2.ulimit -n[num]更改最大打开数量为num，ulimit -a 查看设置权限
	ulimit -n2020

	
动态库和静态库
查看当前程序依赖的动态库文件：ldd+可执行程序
	例：ldd vfork  libc.so.6 ---> C动态库 包括(ls,mv等等)
	ldd+静态链接文件 not a dynamic executable
查看文件属性：file+可执行程序
	file vfork
	1.动态库
	libc.so.6 => /lib64/libc.so.6 (0x00007fc458bb9000) C动态库
	生成动态库
	gcc/g++ 库文件.c -shared -fPIC -o 库.o  
	生成动态库相当于头文件指向函数的实现文件，函数声明都在.h头文件，函数实现在.c库文件，然后生成库
	
	指定动态库
	gcc main.c -o main -L ./ -l库里面的函数 
	编译动态库的源码中不能出现main函数
	编译可执行程序时，必须告诉编译器链接的动态库是哪个？，否则发生链接错误。指定链接动态库所在路径和名字，
	gcc main.c -o main -L . -lfunc  (-L+路径，-l+库的名称)，可执行程序在找动态库时会默认在当前路径下寻找
	若把动态库移到别的地方：移回来或者把位置放到环境变量中，就不会发生链接错误
	
静态库  必须加static 不然就是动态链接
	Windows中静态库是以.lib为后缀的，动态库为.dll，编译依赖.lib库文件，运行时依赖.dll文件
	生成
	gcc/g++
	shared fPIC
	-o后面生成的动态库名字
		前缀：lib
		后缀：io
	ar -rc libfunc.a test.c   用源码会报错
	先gcc -c test.c -o test.o  生成汇编
	ar -rc libfunc.a test.o（这个依赖文件为.o汇编之后的，不是原文件）
	使用
	gcc main.c -o main -L . -lfunc 
	
动态链接和静态链接最大区别：有没有static
静态库用动态方式链接，文件会很大，但把生成的库删除，仍然可以执行

文件系统
线性存储方式可能会导致磁盘利用率较低，离散式存储能提高磁盘利用率，ext2文件系统就是采用了离散式存储，每个比特位表示Data blocks中块的使用情况，为1表示占用，0表示空闲

文件存储：在BlockBitMap中查找空闲block块，将文件存储在空闲的block块当中，再通过inode BitMap获取空闲的inode节点，在空闲的inode节点描述文件在DataBlock区域当中存储的位置
inode

软硬链接
	软链接(类似快捷方式或者说别名)：In -s hello aaa 
	它只会在你选定的位置上（不写位置默认当前路径下）生成一个文件的镜像，不会占用磁盘空间
	ll -i 可以看到两个的inode节点号不同，软链接文件具有独立的inode节点号
	在删除软链接文件或者软链接文件指向的原文件时，两者都应该同时删除
	硬链接：In hello bbb
	ll- i 可以看到两个的inode节点一模一样，一个文件生成了两个有效路径
	问题：为什么删除原文件之后，硬链接的文件仍然存在？
	因为硬链接是在选定的位置上生成一个和源文件大小相同的文件，硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能
无论是软链接还是硬链接，文件都保持同步变化
*/

/*
进程间通信
为什么需要进程间通信？
进程都拥有自己独立的虚拟地址空间，造成了进程的独立性，通过进程间通信，可以让不同进程进行协作(数据交换或者进程控制)，例QQ中交流
网络就是一个进程间通信，信息在不同进程中传递
1.管道
	管道符 | 链接两个命令，把第一个输出的结果给第二个命令作为输入
	管道本质就是在内核当中开辟的一块内存，也可以称之为内核缓冲区，这段空间没有标识符，因此其他进程也就无法
	用户态        ps aux | grep xxx
	内核态             缓冲区	ps -aux被加载到缓冲区，然后给grep xxx
匿名管道
	在内核中创建出来的一块内存是没有标识符的,所以管道开辟的内存没有
	如何创建一个管道？int pipe(int  fd[2])；fd[2]整形数组，保存的是文件描述符(新创建两个文件描述符fd[0]=3读端,fd[1]=4写端，0：标准输入，1：标准输出，3：标准错误)，两个元素。fd[0]：读端，读匿名内存,fd[1]：写端，数据流向由写端--->流向读端
	fd是输出型参数，用时不需要输入值
	成功返回0；失败-1
	int fd[2]; int a=pipe(fd);
	闪烁原因：1.指向内核的内存 2.不存在
	
进程标识符也就是进程号，也就是pid
每个进程(task_struct)，其实都是一个双向链表将所有进程链接，优点:方便CPU调度，当一个进程结束，则这个双向链表清除一个节点，但有一个特殊的，僵尸进程！！尽管退出但不会被双向链表清除
在pipe的程序中，写入操作，写入了内存的缓冲区(之前一直在想管道是连接两个进程，那写入了哪一个进程呢，其实没有写入进程，而是写入了匿名管道)，读出来之后缓冲区中的就没了
查看进程调用栈：pstack + 进程号，应该从下往上看，可以看到25行卡住调用栈，因为管道中没有内容了。

因为读端读过之后，内存缓冲区就没数据了，所以管道的数据流只能是从写-->读，但读端可以决定每次读多少字节
管道生命周期跟随进程退出而结束
用于获取进程标识符的信息，int flag=fcntl(int fd，int cmd，...)...是可变参数列表
flag = 0代表只读，1代表写，f[0]读端--->O_RDONLY，f[1]写端--->O_WRONLY，
因为管道在内存缓冲区中是没有pid的，所以必须是具有亲缘关系的(父子进程)才能操作同一个内存缓冲区，因此必须先创建管道，再创建子进程(拷贝task_struct结构体,里面有files_struct结构体，里面放着文件描述符)
子进程输入，父进程读取，这就是进程间通信

管道在内存的缓冲区有多大（能存多少字节）：64k  pipe_buf==4k 同时写入时，最大写入4k就要切换另一个，写入4k，再切换回来，写入小于4k则保证原子性
临界资源：同一时刻，当前的资源是能被一个进程所访问，如果多个进程同时去修改临界资源，可能会导致数据二义性
如何保证对临界资源访问的合理性，即不会造成数据二义？
互斥：同一时刻，保证只能有一个进程访问
同步：保证了进程对临界访问的合理性
读写端默认为阻塞(写入的数据，读两次，第二次读会阻塞)，非阻塞O_NONBLOCK
int flag = fcntl(fd,F_GETFL);	F_GETFL:获取文件描述符的属性
fcntl(fd,F_SETFL,flag | NONBLOCK); F_SETFL：设置文件属性（当前是读且非阻塞）因为每一个比特位都表示不同含义
为什么要与，NONBLOCK八进制是400，转换成二进制有1的位置是代表非阻塞，和flag与就能非阻塞还带有flag的属性
写端为非阻塞(子进程一直写),读端关闭(父进程)，当管道满了，程序会把write的进程退出(子进程)，但这时父进程还在while无限循环，造成僵尸进程
	
阻塞了的进程会退出吗？
不会退出，进程会一直卡住
下来测试父子进程中都输出，多次运行看父子进程谁先走，两个依次while循环
测试结果父子进程不一定谁先运行

下面是4种情况
1.写端非阻塞
	1.读端关闭，写端一直写，写满后，write收到管道破裂信号SIGPIPE，进程直接被退出，如果子进程是写端可能会造成僵尸进程
	2.读端不关闭，但也不读，write一直写，写到满时返回-1并报错资源不可用
2.读端非阻塞
	1.写端关闭，读端一直读，read返回0
	2.写端不关闭，读端一直读，read返回-1，表示资源不可用(管道为空)

命名管道：
创建：
命名管道标识符大小为0，它只是一个管道文件，真正存储的位置在内核缓冲区
int ret = mkfifo("./fifo.test",0664); //在当前目录创建fifo.test为名管道，权限0664
if(ret<0)
{
	perror("mkfifo");
	return -1;
}
int fd = open("./fifo.test",O_RDONLY);以只读打开命名管道
特点：
1.生命周期：跟随程序(进程)
2.具有标识符(fifo)，因此两个进程不需要具有亲缘关系，就可以进行进程间通信
3.其它特点：匿名管道相同
//////////////////////////////////////////////////////////////////////////////////////////////

共享内存：
虽然不同进程具有不同的虚拟内存空间，但映射同一块物理内存，而且虚拟地址中间有一块共享区，
这块共享区映射了物理内存的一块共享内存，操作这段共享区则可实现进程间通信。具体操作方式：
在共享内存开辟一段空间，不同的进程可以把这段空间附加到自己的共享区中，这些进程可以通过
共享区来交换数据。
	画一个图来解释这个现象
共享区操作原理:
1.先在物理内存中开辟一段空间
2.各个进程通过页表把这段物理内存映射到自己的虚拟内存地址
3.不同进程对共享内存区域进行读之后，这段内存的数据并不会被清除

1.创建：
	int shmget(key_t key，size_t size，int shmflg)；
	int shmid=shmget(KEY,1024,IPC_CREAT|0664); 
	key：共享内存段的名字，可以任意设置，但不能和操作系统中其它内存段名字一样 
		用例:#define key 0x9999999
	size：共享内存大小，单位为字节
	shmflg：用或的结果
	IPC_CREAT：不存在则创建共享内存，如果存在则返回共享内存的造作句柄（有点类似文件描述符）
	IPC_EXCL：是一个辅助，提示信息
	IPC_CREAT | IPC_EXCL：1.以key为名的共享内存已存在，则报错。2.不存在并创建，返回操作句柄
返回值：返回共享内存的操作句柄（有点类似文件描述符）
问题：标识符key用来表示共享内存，它是一个地址吗？
不是，在Linux中可以把它理解成一个内存段的名字，

共享内存段名和共享内存的操作句柄的区别：
	操作句柄(shmget的返回值ret)：通过句柄，进程可以对共享内存进行操作(附加，分离，删除等)
	内存段名(key)：不同进程通过内存段名可以找到共享内存，是用来识别共享内存的

2.删除共享内存：
	ipcrm -m+[操作句柄]
3.将共享内存附加到一个进程：
	void* shmat(int shmid，const void* shmaddr，int shmflg);
	void* lp=shmat(shmid,NULL,0);
	shmid:共享内存操作句柄
	shmaddr：指定将物理内存映射到哪一个虚拟地址，一般都写NULL操作系统自动选择一个虚拟地址，并把进程附加到共享内存中
	shmflg：一般都为0：可读可写
	SHM_RDONLY：只读

返回值：成功返回指针，指向共享内存的地址，操作这个地址就可以操作物理内存了。失败返回-1
用例：void* lp = shmat(shmid，NULL，0)；0代表可读可写，返回的lp是一个地址，
4.将共享内存段和当前进程分离：
	int shmdt(const void* shmaddr);
	shmaddr:由shmat返回的指针
注意注意！！：将共享内存段与当前进程脱离不等于删除共享内存段
5.操作共享内存
	int shmctl(int shmid, int cmd, struct shmid_ds *buf);
	shmid:由shmget返回的共享内存句柄
	cmd:将要采取的动作（有三个可取值），
获取	IPC_STAT：读取当前共享内存的属性信息(比如共享内存的大小，创建时间等等)，放在buf里
设置	IPC_SET：设置共享内存的属性信息，创建一个结构体shmid_ds buf，用他的内容去设置
删除	IPC_RMID：删除共享内存，buf可为NULL
	buf:字符数组
	用例：删除：shmctl(shmid，IPC_RMID，NULL)；
获取共享内存信息：shmctl(shmid，IPC_STAT，&buf)；printf("shm_size=%d\n"，buf.segsz);输出结构体buf中segsz(共享内存大小)

到此删除共享内存有了两种方法：1.ipcrm -m+[操作句柄] 2.shmctl(操作句柄, IPC_RMID, NULL);
需要注意的是：有错误！
1.删除之后共享内存就被释放了，所以其它附加的进程再进行读写操作会报错，共享内存名(key)被设置成0x00000000，状态被设为dest
2.删除之后，若还有其它进程附加在这段共享内存上，则用ipcs -m任然可以查看到这个共享内存的存在
两个进程附加到共享区，一个进程删除共享区并分离，查看共享区任然存在，但是状态是destroy，另一个进程也分离或退出则该共享区被销毁，找不见

删除共享内存总结：
1.将该共享内存的状态标记为dest，将标识符设置为0x00000000，任何进程都不能再进行附加，同时会释放共享内存
2.风险：如果还有进程附加在该被删除的共享内存上，有可能访问到非法的内存，导致程序越界并崩溃。输入ipcs -m仍然可以看到这块共享内存
3.当附加程序全部分离或者退出，操作系统内核也会随之将描述共享内存的结构体释放掉，也就是说ipcs -m看不到我们所创建的了
查看共享区：ipcs -m
key(标识符) shmid(操作句柄) 拥有者 权限 空间大小 附加进程数量 状态
结论：
1.生命周期：跟随操作系统内核
2.进程在读取共享内存之后，共享内存内容不变，类似拷贝
3.一个进程删除共享内存后，共享内存被释放，其它未附加的进程找不见这段内存，但ipcs -m任可以看到这段共享内存，等所有附加进程都分离时，该共享内存就找不见了

消息队列：底层实现就是内核当中创建的链表
1.保存着不同类型，不同类型优先级不同
2.同一类型先进先出 
特性：
	1.生命周期是跟随内核的
	2.可以进行双工通信，因为数据有明显的数据边界了，克服了管道当中无格式的字节流的缺点
信号量：
	system V版本 sem
	posix sem(多线程)
	信号量的底层是一个计数器，信号量是用来进程控制的
临界资源：多个进程都能访问的资源，被称为临界资源
		  多线程中，多个线程都能访问到的资源，被称为临界资源
临界区：访问临界资源的那一块代码

面试题：列举你所知的进程间通信（管道，共享内存，消息队列，信号，网络，unix域套接字，信号量）
*/
/*
	SHELL是命令行解释器的统称，bash是一个可执行程序(命令行解释程序)也可以说是一个进程，而输入的命令也是可执行程序，
	在bash中输入一个命令，bash先创建一个子进程，然后进程程序替换成该命令的代码并运行，bash就自动切换到后台了。
	问题：不是都已经程序替换了嘛，为什么bash还会回收他的资源，那程序替换之后会不会有僵尸进程？
	把一个进程放到后台去运行，在启动命令之后加&
	fg：就把刚才放到后台的进程，再放到前台运行

进程信号，信号概念，产生，注册，注销，捕捉处理，自定义信号处理函数
概念：
	查看信号列表：kill -l
	1.信号是一个软件中断，打断当前正在运行的进程，让该进程去处理信号的事件
	2.信号的种类：
		1-31：非可靠信号，当前信号可能会丢失(例：多个2号信号进入，可能只处理一个2号信号) 
		34-64可靠信号，该信号不会丢失
	3.信号产生：
	硬件产生：ctrl + c (退出一个进程)：SIGINT(2号信号)，这是发送给前台进程的。
			  ctrl + Z：SIGTSTP（20号信号）
			  ctrl + |：SIGQUIT（3号信号），会产生核心转储文件coredump
			  核心转储：core dumped，存储程序崩溃之后错误的原因
		执行并查看：gdb+可执行程序+coredump文件
		产生coredump文件条件：
			1.ulimit -a中没有限制coredump文件大小，且磁盘空间大小够用
			2.崩溃条件：解引用空指针，内存访问越界，且越界的位置别的进程正在占用，崩溃就会收到（11号信号SIGSEGV），并产生coredump
			3.崩溃条件：多次free释放空间（6号信号SIGABRT），free（NULL）不会崩溃
	软件产生信号：
		int kill(pid_t pid,int signo)或在bash中输入kill -信号种类+pid
		例：kill(getpid(),2);给当前进程发送一个2号信号，2号信号中断
			pid：进程标识符
			signo：信号种类
		abort(pid_t pid)函数：当进程调用到这个函数时就会收到6号信号SIGABRT(double free)，底层封装了kill(getpid(),6);
		man手册中2是系统调用函数，3是库函数
		echo &？：上次如何退出进程的
		alarm定时器函数，alarm(int sec) SIGALRM 时间到了结束进程
		11号信号：SIGSEGV 段错误信号--->可能访问了空指针或访问越界
	4.信号注册的过程
	1个位图(sig[]的比特位)+1个sigqueue队列
	内核源码：find /usr -name sched.h，找到一个include\linux里面有task_struct结构体，ctrl+]可以跳转，task_struct大概在1300行
	创建一个进程则task_struct结构体下有一个struct sigpending结构体叫pending，里有一个双向链表list和sigset_t(位图)结构体内部，保存着数组sig[]，数组中的都是无符号长整型long，每个比特位都表示不同的信号。
	位图sig数组不是按照long类型来使用的，而是按照bit位来使用，每一个信号在该位图中都存在一个比特位对应，为1则表示收到信号
	位图sig数组里有两个元素，代表两个无符号长整型一共128位，从0位开始，但没有0号信号
	非可靠信号：1-31
		更改数组sig[]位图中对应的比特位为1，在sigqueue队列中增加sigqueue节点，多次收到同类型信号时，检查发现sigset_t位图中该比特位已经置1了，则丢弃第二次的信号，不增加sigqueue队列节点。
	可靠信号：34-64，
		更改sig位图当中对应的比特位为1，并且在sigqueue队列中增加对应信号的节点，当多次收到同样信号时，则再次在sigqueue队列中增加对应信号的节点
	5.信号注销的过程
	非可靠信号：
		操作系统先将sigqueue队列当中信号对应的节点拿出来，再将sig位图中对应比特位置0，操作系统是拿着节点去处理信号的。
		注意：这里是先删除再拿着信号节点去处理信号
	可靠信号：
		先将sigqueue队列当中信号对应的节点拿出来，再检查sigqueue队列是否还有同类型节点，有则不改变sig位图对应比特位的1，等待下次处理，无则直接将sig位图对应比特位置0。再拿着sigqueue节点处理信号
	6.信号捕捉处理
	信号有哪些处理方式？
	默认处理方式：SIG_DEL --->执行一个动作(函数)
	忽略处理：SIG_IGN --->不干任何事
		为什么僵尸进程？-->子进程退出时，会给父进程发送一个SIGCHLD（17号）信号，而操作系统对SIGCHLD的信号处理方式为忽略
		僵尸进程无法通过发送kill信号结束！！！
		面试技巧：僵尸进程 扯到--> 信号(忽略处理)--->继续扯到 解决(进程等待、信号处理、信号各种点等等)
	自定义处理：自定义信号的处理函数
1）	sighandler_t signal(int signum，sighandler)：内部也调用了sigaction函数
			signum:需要自定义哪一个信号
			handler：函数指针类型的参数，函数名，该函数可以改变信号处理的方式
	程序运行完这条语句之后，就会记录下，当收到signum号信号时，调用该函数(称为回调函数)
	返回值：sighandler_t：函数指针

	详细说自定义信号处理流程：
	task_struct下有一个结构体指针struct sighand_struct，该结构体里有结构体数组action[]，数组中每个都是struct k_sigaction结构体（这些结构体对应了每一个信号的处理逻辑），里又有结构体struct action sa，里有_sighandler _t类型的元素，这个sighandler_t是一个函数指针类型。_sighandler _t就是函数指针void(*sighandler_t)(int)类型，sa_handler原始指向--->默认处理方式SIG_DEL，修改之后就指向我们自定义的函数了
	操作系统默认对信号的处理：
	当sigset_t位图中收到某个信号则相应比特位被置为1，操作系统处理该信号时，就会从PCB(task_struct)中寻找sighand_struct这个结构体，从而找到sa_handler函数指针，操作系统会通过函数指针保存的地址来调用函数
	自定义信号处理函数
	signal修改的就是函数指针sa_handler保存的函数地址，这样操作系统在处理信号时，通过sa_handler地址就能调用我们自定义的函数
	struct sigaction 结构体
	{
		void  (*sa_handler)(int):函数指针，保存了内核对信号的处理方式
		void  (*as_sigaction)(int,siginfo_t*,void*);要搭配sa_flags使用，为SA_SIGINFO是调用该函数地址
		sigset_t sa_mask 保存的是当进程在处理信号时，收到的信号，也就是位图
		int   sa_flags:要怎么修改 ，一般为0
			值为SA_SIGINFO时，操作系统在处理信号时，调用的就是sa_sigaction函数指针中保存的值
			0在处理信号的时候，调用sa_handler函数指针中保存的函数
		void  (*sa_restorer)(void)预留信息
	}
	问题：signal函数进行信号修改，怎么都会有效呢？？
	谁保存了，这几个信号产生时调用handler所指函数，的信息呢？
	那是谁调用的回调函数呢？
	目前这段代码只有一个主线程，主线程执行main函数中的，当收到2号信号时，执行回调函数的是内核执行流。
	signal是内核在执行的，当收到信号时，打断当前的执行流，去执行内核中的执行流

2） sigaction函数更改信号为自定义处理方式，sigaction结构体里都是以sa_开头的，因此这个结构体叫sa，全称struct sigaction sa
	int sigaction(int signum,const struct sigaction *act,struct sigaction *oldact)
	signum：待更改信号的值
	act：将信号处理函数改为act，act.sa_mask的初始化状态必须是全零，意思是没有收到信号
	oldact：信号之前的处理方式
	位图操作函数：
	int sigemptyset(sigset_t *set);将位图的所有比特位清0
	int sigfillset(sigset_t *set);将位图的所有比特位置1
	int sigaddset(sigset_t *set,int signo);
	int sigdelset(sigset_t *set,int signo);
	int sigismember(const sigset_t *set,int signo);
	问题：在另一个SSH中输入kill -3+pid程序直接运行了起来，getchar（）接收了一个什么？
	getchar()目的是让程序阻塞，接收什么并不用关心
	总结：
	1.signal是改函数指针sa_handler,内部也调用了sigaction函数
	2.sigaction函数是改sigaction结构体

	7.信号的捕捉流程：
	画一个图
	用户态：执行自己定义的代码
		sys_return函数：返回用户空间
	内核态：执行操作系统接口或库函数封装的系统调用函数
		1.要从内核空间到用户空间必定调用do_signal函数：检查(pending中的位图)有没有收到信号，有：则去处理信号，无，则调用sys_return函数返回用户空间。处理完成之后继续调用do_signal函数检查
		2.若有收到信号，1)该信号处理方式是系统调用(例：默认处理方式)，则继续在内核中处理 2)该信号处理方式是我们自定义的，则跳转到用户空间处理信号，处理完成之后调用sig_return函数返回内核，继续调用do_signal检查。
	也就是整个流程分两种：1.执行完系统调用函数之后，调用do_signal函数检查是否收到信号，无则返回
						  2.有则看是哪种处理方式，1.自定义 2.系统调用
	什么时候进入到内核空间：调用系统调用函数的时候，或者调用库函数的时候（库函数底层大多数都是系统调用函数）
	free(NULL)不会崩溃，因为NULL在底层是0
	
	8.信号阻塞 block （9号SIGKILL信号和19号SIGSTOP不能阻塞）
	信号未决(sigpending)：信号从产生到递达之间的状态，递达是实际执行信号处理的动作
	问题：未决信号集就是我们所说的sigqueue队列吗？？？
	是的，未决信号集就是sigqueue队列，但为什么不是先进先出？
	sigset_t位图，操作系统中有两个位图1.pending中：sig[] 2.block中：sig[]，位图也可以自己创建也就是struct k_action sa结构体中的sa_mask位图
	被阻塞的信号产生时，将保持在未决状态，直到进程解除对此信号的阻塞，才能执行递达动作
	阻塞和忽略是不同的概念，阻塞：是在递达之前的动作，阻止递达，忽略：是递达之后可选择的动作
	在task_struct结构体里，有三个信号标志位block阻塞，pending未决，handler函数指针
	画个图！
	注意：
		1.信号的阻塞并不会干扰信号的注册，该注册还是注册，只不过当前进程不能立即处理了
		2.当block位图中对应信号的bit位为1，则表示进程阻塞该信号，当进程进入到内核空间，准备返回用户空间时，调用do_signal函数，这时候不会立即去处理该信号了，之后会处理
		3.收到多个非可靠信号，只会添加一次sigqueue节点，所以处理信号时只处理了一次
		  收到多个可靠信号，会添加多次sigqueue节点，所以处理了多次
	int sigprocmask(int how,const sigset_t *set,sigset_t *oldset);
	读取或更改进程的信号屏蔽字（阻塞信号集）
	how：告诉sigprocmask函数应该做什么操作，注意：下面操作的都是位图！
	SIG_BLOCK：设置某个信号为阻塞
		block(new)=block(old)|set -->按位与
	SIG_UNBLOCK：解除对某个信号的阻塞
		block(new)=block(old)&(~set) -->先取反在按位或
	SIG_SETMASK：替换阻塞位图
		block(new)=set
	set：用来设置阻塞位图
	oldset：原来的阻塞位图

竞态条件：多个执行流访问同一个资源的情况下，会对程序产生二义性的结果，称为竞态条件
	可重入：多个执行流访问同一资源，但不对程序结果产生影响
	不可重入：多个执行流访问同一资源，并且产生了二义性
	在这里每接收一次ctrl+c，内核执行流都会执行一次自定义函数让g_val--，造成了结果的二义性
SIGCHLD：
	子进程退出就会给父进程发送SIGCHLD信号，配合signal处理机制处理
	自定义处理SIGCHLD信号的函数，在函数中用wait处理子进程，这样做可以在收到子进程退出信号时进行处理(内核执行流去调用自定义函数处理)，并且父进程不会因为wait一直等待处理完子进程，才执行
	注意：不能让17号信号SIGCHLD之外的信号定义为调用该函数，若其它信号的sa_handler也指向这个自定义函数，收到该信号时就会阻塞内核执行流(没有子进程退出)
volatile:使变量保持内存可见性，即从内存中读取值，摒弃编译器优化
	-O2优化后一般为了提高执行效率，CPU是在寄存器中取值，但其实该值在内存中内已经改变了，寄存器里的没有改变
	使用volatile可以一直都取出的是内存中的值 
*/
/*
sigqueue队列为什么不是先进先出？
	do_signal函数处理信号时，会先通过pending和block位图计算该处理哪一个节点了，计算出先处理可靠信号的结果，然后再去sigqueue队列中取节点。
top -H -pid：查看CPU使用情况
多线程安全回答：请你解释什么是线程安全或者什么是线程不安全
完整的解释：什么是线程不安全以及怎么去解决线程不安全的现象
	固定模板：结论(总体)：线程不安全会导致程序结果产生二义性
		1.举例假设：有多个线程(例线程A和线程B)在并发运行，并且都要操作一个全局变量10
		2.线程A和线程B在入口函数中都对这个全局变量进行了++操作
		3.不安全产生的原因：线程A拥有CPU之后，对全局变量进行++操作，并非原子性的操作(不是直接把++执行完毕，并回写到内存)，也就是可能在中间被打断
		4.假设线程A刚把g_val从内存中读到CPU的寄存器中，就被切换出去了(程序计数器保存此时执行的位置，上下文数据保存寄存器中的数据)，
		5.而这时线程B拿到时间片对，g_val进行++操作，并且执行完成了，则内存中是11
		6.线程A再次拿到时间片，恢复现场，继续往下执行，从上下文数据和程序计数器中读取到刚才的10，并进行+1会写到内存还是11
		7.理论上这两个线程各自++一次，g_val应该为12，因此造成二义性
		8.马上说怎么去解决：进程锁，进程怎么加锁，怎么去开锁。
		画个图说被打断的点，有四种可能，1.内存到寄存器  2.寄存器到cpu  3.CPU回写到寄存器  4。寄存器回写到内存
*/
/*
多线程：
为什么要有多线程？
	创建一个线程相当于创建了一个执行流，程序中不仅仅只有一个main函数的执行流，而是有很多个执行流在同一时刻拿着不同的CPU进行运算，称为并行。同一时间有多个执行流同时执行代码，程序的运行效率可以大大提高
线程是什么？
	线程就是创建出来的执行流，在内核中拷贝当前进程PCB创建了一块PCB（task_struct结构体），共用一块虚拟地址空间
	1.创建子进程概念(fork,vfork)
		fork:子进程拷贝父进程的PCB创建出来一块PCB，PCB被内核用双向链表管理起来，此时父子进程用了同一块虚拟地址空间，当父子进程内容即将发生改变时给子进程重新开辟一块虚拟地址空间(写时拷贝技术)
		vfork:子进程拷贝父进程的PCB，两个PCB一模一样，并且指向同一块虚拟内存空间，子进程先运行，父进程阻塞直到子进程退出
		调用栈混乱问题：子进程提前退出并释放了资源，vfork为了解决这个问题，让子进程先一直运行，直到退出父进程才开始运行
	2.创建线程的概念
		pthreat_create:在内核中创建一个PCB(task_struct)结构体，这个线程(执行流)的PCB和当前进程PCB一样，并且共用同一块虚拟地址空间，在虚拟地址空间的共享区，线程会有自己独有的东西
		linux中其实是没有线程概念(这是C库中的概念)，linux中叫它轻量级进程，线程的接口都是C库提供的，底层调用clone()接口
		在bash中输入ps aux 看到的pid其实是tgid(thread group id)线程组，而pid是线程的id，每个线程的pid都是不一样的。1）当一个进程中只有一个执行流（main函数执行流）时，我们称这个tgid也是pid。主线程的pid也是tgid也就是pstack中最下面的。
		相当于进程是一个大家，而线程是家里的成员(每个成员id不同)，当家里只有一个人，也称这个人就是家。
		注意：线程是操作系统调度的最小单位，进程是操作系统分配资源的最小单位
线程的优点：
	1.创建一个线程比创建进程的开销小(不用创建虚拟地址空间，页表，段表等等)，且一些内容是共享的可以直接使用(例：数据段，代码段内容)
	2.不同线程可以并行，提高了进程运行效率，例如：第一个线程运行代码的1~5段，第二个线程运行代码的6~10段
		并行：同一时刻不同线程占用不同CPU运行处理(十个人并排过桥)
		并发(串行)：同一时刻只能有一个线程占用CPU处理(排排队过独木桥)
线程的缺点：画一个滑稽吃鸡
	1.健壮性/鲁棒性低(和2的道理一样，缺乏安全性：一个崩溃全盘崩溃)
	2.多线程的程序有多个执行流，当其中一个执行流异常，进而触发信号机制，会导致整个进程退出，所有线程也随之退出(桌子被掀翻)
	3.缺乏访问控制(不同的线程抢占同一资源，可能造成程序结果二义性)
	4.编程难度高，多个执行流可以并发的执行，也就可能会访问到同一临界资源，我们需要对访问临界资源的顺序进行控制，防止程序产生二义性
		万恶之源：内核中创建一个线程也就相当于在内核中创建了一块PCB，内核进行调度PCB时，由于并行式运行，所以可能导致程序结果产生二义性，也就是抢占式执行
	5.性能损失，一个进程拥有很多个线程时，操作系统会不停的进行切换调度，而每次切换都要保存上下文信息(当前代码执行的信息和数据)和程序计数器(程序执行到代码哪一行)、上下文数据等，(重新拿到时间片)回调时会占用CPU先执行处理上下文信息，程序计数器。
	总结：
	1.线程和进程拥有同一虚拟内存空间，且线程是并发式执行，即新增了一条执行流
	2.一个资源最多只能有一个线程使用，因此要保证对临界资源的顺序访问

线程的独有和共享：画一个图
独有：(共享区内一块独有的)
	1.tid:线程id(LWP)
	2.栈空间：因此线程不会造成调用栈混乱，因为每个线程在共享区都有独有的栈，一个进程的栈空间默认8M，用ulimit -s可修改
	3.信号屏蔽字:个人猜测-->信号阻塞的位图每个线程都不同，是的！
	4.调度优先级：哪一个线程先运行
	5.errno：调用接口收到的错误信息
	6.一组寄存器：保存当前线程切换时的上下文信息，程序计数器等
共享：(虚拟地址空间中其它的)
	1.共享当前进程的虚拟地址空间(内核，环境参数，数据段，代码段)
	2.文件描述符表：(struct files_struct结构体中保存的那个fd_array[]数组，数组的每个元素都保存着不同文件描述信息)
	3.当前进程的工作路径，例运行程序时的./test
	4.用户ID和用户组ID
	5.信号的处理方式(SIG_DFL,SIG_IGN,自定义)
总结：线程拥有独有栈因此可以并行，不用担心调用栈混乱

线程和进程的区别：
	多进程：1.每个进程拥有自己的虚拟地址空间，且一个进程异常不会影响其他进程，
			2.多进程也能提高程序运行效率(本质也是增加执行流)，但需要用到进程间通信(访问共享内存，命名管道)
	多线程：1.每个线程都共用了一块虚拟地址空间，且只要有一个线程异常崩溃则整个进程崩溃
			2.多线程可提高程序运行效率，但程序健壮性低，代码编写复杂因为要避免二义性(并发执行带来的后果)

线程控制：创建，终止，等待，分离
	前提：线程控制当中的接口都是库函数，所以线程控制的接口需要链接线程库，线程库的名称叫pthread，链接的时候增加lpthread。且大多函数都以pthread开头，pthread_t：线程ID
	创建：
		int pthread_creat(pthread_t* thread,const pthread_attr,void* (*thread_start)(void*),void* arg);
		用例：pthread_creat(&tid,NULL,func,NULL);
			thread:线程标识符pthread_t，是一个出参，和线程id并不是一回事，pthread_t本质就是线程在共享区独有空间的首地址，通过这个标识符可以对当前线程进行操作，调用pthread_creat作为出参返返回给调用者。这个标识符也就是我们用pthread_t tid;创建出来，并传入create函数的"出参"
			attr:线程属性,pthread_attr_t是一个结构体，这个结构体完成对新创建线程属性的设置。(NULL是默认属性，一般都是用NULL)
				属性有：线程栈的大小、线程栈的起始位置、线程的分离属性、线程的优先级调度属性
			thread_start:线程入口函数，接收一个函数地址(可以自定义)，这个函数的返回值是void*，参数也是void*
			arg：给线程入口函数传递的参数的值,类型是void* ，一般这个参数也是传的NULL
				注意：不能传递临时变量，arg不能接收临时变量，可以传递在堆上开辟的内存
			返回值：==0创建成功，<0创建失败
	注意：
	1.在传一个堆上开辟的结构体指针时，发现输出并不是先执行0号线程，而是随机执行，这就是抢占式执行，但要在线程函数结束的位置释放掉堆上申请的空间
	2.void* arg不能接收临时变量的地址，这是因为主线程和线程是并行式运行，而临时变量在出了主线程的作用域，就会在栈帧上被释放资源，而此时线程中还在使用这个非法地址，可能造成程序崩溃(如果这段空间被新的资源开辟)。
	3.void* arg可以接收堆上开辟的，如结构体指针，this指针。因为堆上动态开辟的资源需要手动释放，不要忘记在线程退出之前释放掉堆上的资源。

	画个图，画了
	总结：
	1.pthread_t是线程标识符，在内核的本质就是线程独有空间的首地址！用pstack+pid，可以看到LWP前面那一串就是pthread_t线程标识符。
	2.getpid()获取的是进程ID即tgid，不管是在工作线程还是在主线程。gettid()获取的是线程ID即pid，可以用#include<sys/syscall.h>; pid_t tid = syscall(SYS_gettid);来获取线程ID
	3.pthread_creat是C库中函数，在用户态进行运行。创建出来的是用户级线程，在内核中通过LWP进行调度
	4.为了避免越界访问，只能给arg传堆上开辟的空间。
	5.轻量级进程在内核中就是一个PCB，内核通过对PCB的调度实现了对线程的调度。轻量级进程ID即pid，每一个pid都是不相同的，但是他们的进程组ID即tgid是一样的，也可以叫主线程ID或者进程ID。
问题：堆上的空间是共享的还是独有的?如果是共享的，那一个线程释放，别的线程释放不会崩溃？
在这段代码里面，他在for循环开辟了多段堆空间，所以传进去的每个堆地址都不同，因此每次释放的地址都不一样

线程终止的方式：
	1.线程入口函数的return返回，在主线程中调用return的效果相当于调用_exit()，整个进程都会退出
	2.pthread_exit(void* retval)：谁调用谁退出
		retval：当前线程退出信息，可以是NULL
		当主线程(也就是main函数的线程)调用pthread_exit退出的时候，进程并不会退出，因此主线程变成了"僵尸线程"，而工作线程的状态还是R或者S
	3.pthread_cancel(pthread_t thread)：结束指定的线程，结束传入的线程标识的那个线程，也就是线程标识符为thread的线程，这个标识符可以是pthread_create()函数的出参，也可以用pthread_t pthread_self()获取自己的线程标识符
		thread:线程的标识符
		用例:pthread_cancel(pthread_self());结束当前线程
		pthread_cancel()并不是立即退出！！！！要等待一小会，这个时间不会超过1s，会看到打印了一行。
	pthread_t线程标识符：一定得记住！！！

	注意：线程在默认创建的时候，默认属性当中认为线程是joinable的
		joinable属性:当线程在退出的时候，需要其他线程来回收该线程的退出信息(资源)，如果没有任何线程去回收，则共享区中对于退出线程的空间还是保留的，退出资源没有完全释放而造成内存泄露。(类似僵尸进程)
总结：
	1.在main函数里用return,exit(),_exit,kill是退出当前进程，因此所有线程都退出
	2.在main函数里调用pthread_exit和pthread_cacel，退出了当前主线程，但进程不会退出，因此造成僵尸线程

线程等待：为了释放线程退出资源，防止内存泄露
	pthread_join(pthread_t,void**) 这是一个阻塞接口
		pthread_t：线程标识符
		void**：获取线程退出的什么东西，线程不同的退出方式会收到不同的值，一般是传NULL
			return:接收入口函数return返回的内容，
			pthread_exit:获取pthread_exit(void*)的参数
			pthread_cancel：获取到一个常数，PTHERAD_CANCELED：#define PTHERAD_CANCELED (void*)(-1)
	工作线程的资源可以由主线程来回收，主线程(进程)的资源由它的父进程bash(1号进程)来回收。
	这样引起了一个问题：1.若不等待处理线程退出，会造成内存泄露 2.若等待处理线程，因为是阻塞接口，则必须另一个线程专门等待他退出并回收资源(监护人)

线程分离：改变线程的joinable属性，变成detach，从而使该线程退出时不需要其他线程来回收该线程的资源，可以被操作系统来回收
	pthread_detach(pthread_t tid);	detach(分离)
		tid:线程标识符，设置tid为detach属性
	分离的本质是给线程设置了一个属性
	分离可以线程自己分离，也可以是组内其他线程通过获取到线程标识符去分离

重入概念：同一个函数被不同的执行流调用(线程入口函数)，当一个执行流还没执行完，另一个执行流再次进入，就叫重入
	函数可重入：多个执行流同时调用同一函数，不会对运行结果产生影响则为可重入
	函数不可重入：对运行结果产生了二义性
	常见不可重入：
		1.函数在堆上申请了空间(malloc,new)，堆是所有线程共享的
		2.函数调用了I/O库函数，标准I/O库的很多实现都以不可重入的方式使用全局数据结构，并且文件描述符是共享的
		3.使用静态或全局数据
函数可重入！=线程安全
	函数可重入则一定线程安全，而线程安全不一定可重入，即可重入函数是线程安全函数的一种

线程安全：(多个线程并发的访问临界资源，不会导致程序的结果产生二义性则称线程安全)
	线程对临界资源的访问方式：访问是非原子性操作，也就是可能在中途会被打断，并保存当前上下文数据和程序计数器，等待下次处理
	临界资源：多个执行流共享的资源，同一时刻只能有一个执行流访问，若多个线程同时访问可能造成二义性
	临界区：访问临界资源的代码就叫临界区
	原子性操作：操作是一步完成的，意思就是：执行中没有被打断，完整的执行了一个运算并回写到内存中。例如++或者--等操作
	画个图：CPU--寄存器--内存  上下文信息==上下文数据(寄存器中保存的值)  程序计数器
		解释黄牛抢票现象：(一张票被抢了多次)
		1.一个线程在执行--操作时，还没执行完毕，在寄存器中保存的是100，这时该线程运行时间到了，保存了上下文数据(寄存器中的100)和程序计数器
		2.另一个线程也执行--时，完完整整的执行完了，也就是g_val被--成99，且回写到内存中了
		3.这时第一个线程拿到时间片去执行未处理完成的，把100--了一次，又是99，造成二义性，原本--两次应该是98
	面试时：什么叫线程安全？
		可以模拟一个执行流A和执行流B，来讲述对CPU的使用和被打断，造成二义性，并讲述如何解决，然后把代码抠出来
	总结：线程执行顺序内存---寄存器---CPU  4个步骤，缺一就是非原子性，这里有点类似管道中造成二义性，也要求保证互斥和同步
	对应汇编指令：load-->从内存加载到到寄存器，update-->更新寄存器的值进行--，store-->将寄存器的值回写到内存中

	问题：互斥锁在内核中是什么？至少是一个所有线程共享的内容。
		pthread_mutex_t：是结构体类型

如何保证线程的安全性：
	互斥(互斥锁加锁)：在同一时刻只能有一个执行流访问临界资源(关闭厕门，拒绝其他人继续进去)
	同步：程序对临界资源的合理访问,也就是不同类型的线程顺序访问，一个类型的执行流访问完成就切换，这里切换是操作系统调度的，抢占式执行(厕门打开，抢上厕所)。
互斥锁：是一个阻塞接口
	使用互斥锁来保证互斥属性，互斥锁的底层是互斥量，互斥量的本质是一个计数器，有0和1
		0：无法获取互斥锁，即临界资源无法访问(关厕门)
		1：可以获取互斥锁，即(离开并开厕门)
	整个流程：
		int g_val = 10;  临界资源
		执行流A          去访问			
		加锁-->使用互斥锁提供的加锁接口，成功则获取互斥锁，并执行接下来的代码，获取临界资源并处理
			互斥量计数器值为1，成功获取互斥锁，正常返回，访问临界资源
			互斥量计数器值为0，无法获取互斥锁，当前互斥锁接口阻塞，等待互斥量计数器变为1
		g_val--;         执行访问并计算
		解锁			 访问完毕

	加锁操作：对互斥锁中的互斥量计数器-1，实现本质是交换寄存器中的1和内存中的0
	解锁操作：对互斥锁中的互斥量计数器+1
	那么引出一个问题：互斥量计数器本身也是一个变量，那这个变量的取值进行++、--时，会是原子性的操作吗？
		mutex_val：0/1  计数器中的变量
		画个图：互斥变量的内容变化
		寄存器中的值(默认给0)和内存中互斥量计数器的值进行交换，这个操作是原子性的，在汇编中的指令是xchgb，由于只有一条指令保证了原子性

总结：完整的解释加锁流程
	  1.当计数器中的值为1时，表示可以加锁，寄存器中的0和内存中计数器的1交换，相当于给寄存器++了
	  2.当计数器中的值为0时。表示不能加锁，寄存器中的0和内存中计数器的0交换，没有对寄存器的值做到修改，因此请求加锁的执行流阻塞等待，直到计数器为1
	  3.加锁的操作是原子性的
	  4.volatile无法解决这里的问题，这里是从内存中取出数据之后，线程运行时间停止。而volatile是拿数据的时候从内存中取。

互斥锁的使用流程：
	1.定义互斥锁
		pthread_mutex_t:互斥锁变量类型，mutex(互斥锁)，在内核中是一个结构体
			用例：pthread_mutex_t lock;
	2.初始化互斥量
		动态初始化：
		int pthread_mutex_init(pthread_mutex_t* mutex,const pthread_mutexattr_t* attr)
			用例：pthread_mutex_init(&lock,NULL);
			mutex:互斥锁变量，传参的时候传入互斥锁变量的地址
			attr：互斥锁的属性，一般用NULL
		静态初始化：pthread_mutex_t lock=PTHREAD_MUTEX_INITIALIZER;
			PTHREAD_MUTEX_INITIALIZER ：宏定义了结构体pthread_mutex_t(互斥锁)的值
			
	3.加锁
		1.int pthread_mutex_lock(pthread_mutex_t* mutex);	这是一个阻塞接口
			用例:pthread_mutex_lock(&lock);
			mutex:传阻塞变量的地址，&lock
			注意：该加锁方式是阻塞接口
				若计数器为1，则上锁，计数器清0，并执行之后代码
				若计数器为0，则不可上锁，阻塞等待直到解锁，不能执行下面代码
		2.int pthread_mutex_trylock(pthread_mutex_t* mutex)；非阻塞加锁，不会阻塞等待(直接返回EBUSY)，一般要循环等待解锁，不然线程会直接往下执行会访问到临界资源，造成二义性
			mutex:传阻塞变量的地址,&lock
			注意：该加锁方式是非阻塞
				若计数器为1，则加锁，计数器清0，并执行之后代码
				若计数器为0，则不可加锁，接口返回EBUSY(拿不到互斥锁)，要循环进行加锁操作，防止该执行流返回EBUSY之后，直接往下执行代码，造成二义性的结果
		3.int pthread_mutex_timedlock(pthread_mutex_t* mutex,const struct timespec* abs_timeout);阻塞等待一定时间之后，若还没获取互斥锁，则报错返回ETIMEOUT
			mutex:传阻塞变量的地址，&lock
			abs_timeout:加锁时的最长等待时间，超过时间还未加锁报错返回，有两个变量：一个是秒，一个是纳秒
	4.解锁
		int pthread_mutex_unlock(pthread_mutex_t* mutex);
			三种加锁方式都可以解锁(万能钥匙)，
			注意：要在所有可能退出获得互斥锁线程的地方都加上解锁！！！！非常重要，一旦上锁的线程没解锁就退出，其它线程会一直阻塞。
			锁子只有一个！！！
	5.销毁互斥锁
		int pthread_mutex_destroy(pthread_mutex_t* mutex);
			互斥锁销毁，若使用完成后不进行销毁，造成内存泄露
	注意：
		互斥锁的
		1.定义位置：C语言需要在不同函数中使用互斥锁，因此定义为全局变量
						  C++通常定义为类的成员变量，在类中使用
		2.初始化位置：在创建线程之前
		3.销毁位置：必须在线程退出之后，进行销毁互斥锁变量，防止内存泄露
		4.在哪加锁：所有访问临界资源的位置之前
		5.在哪解锁：在所有可能退出线程的地方都要解锁。否则可能会造成死锁的现象。

	死锁：
		1.什么是死锁：一个执行流拿到锁没有释放锁资源就退出，会导致其它想要获取该互斥锁的执行流陷入阻塞等待，这种情况称为死锁。
		介绍一种死锁情况环锁：
			画个环锁的图
			A(1)--->2
			B(2)--->1	执行流AB都陷入阻塞等待，且没有办法进行解锁。唯一解决：重启程序
			调试程序的操作：
				t 3 进入线程3
				bt  查看调用栈
				f 3 查看第3行代码
				p lock2 里面的owner==线程id(pid)
				p lock1 里面的owner==线程id(pid)
				thread apply all bt 查看所有线程的调用栈
		2.死锁的4个必要条件(形成死锁的4个原因)：
			不可剥夺：只有当前获取互斥锁的线程可以进行解锁
			互斥：一把锁同一时刻只能被一个执行流所占用(4个线程最后剩3个(有一个退出)，且程序卡住)
			请求与保持：当期执行流已经占用了一个互斥锁1，还申请新的互斥锁2，被阻塞，互斥锁1无法解锁(环型死锁)
			循环等待：若干执行流在请求锁资源的情况下，形成了一种头尾衔接的循环等待资源(输出100后卡住，未解锁又去循环了)
		3.避免死锁的方法
			1.破坏必要条件
			2.加锁顺序一致
			3.不要忘记解锁：线程可能退出的地方都要进行解锁
			4.一次性分配资源：执行流在完成某件事时，一次性把需要的锁资源都拿过来(拿过来之前已经被解锁)，用完再解锁

总结：
1.在访问临界资源之前进行加锁操作，
2.在所有退出的地方都应该进行解锁操作
3.加锁操作有点像，我们去某个地方(厕所)设置一个门卫，门里有人则不放行
4.发送信号是在解锁之后！！！
5.用continue实现同步，疯狂判断，浪费CPU资源，入等待队列之后，挂起等待，因此不会浪费CPU资源

同步：同步保证了各个执行流对临界资源访问的合理性，通俗来讲：也就是一个执行流访问一次，就切换另一个访问
条件变量：什么是条件变量？
	本质=PCB等待队列+两个接口(等待接口+唤醒接口)
	条件变量接口：
		1.定义条件变量：
			pthread_cond_t 条件变量类型
			用例：pthread_cond_t cond; 
				cond：条件变量类型的变量
		2.初始化条件变量：
			动态：使用完毕需要调用pthread_cond_destroy()销毁
			pthread_cond_init(pthread_cond_t* cond，pthread_condattr_t* attr)；attrutibe:属性
				pthread_cond_t*：条件变量类型变量的地址
				pthread_condattr_t*：条件变量的属性，一般传NULL，默认属性
			静态：使用完毕不用销毁
			pthread_cond_t cond=PTHREAD_COND_INITIALIZER; (initialize：初始化)
		3.等待接口：将调用该等待接口的执行流放到PCB等待队列当中去，进行等待
			int pthread_cond_wait(pthread_cond_t* cond,pthread_mutex_t* mutex)
				pthread_cond_t*:传入条件变量类型变量的地址
				pthread_mutex_t*：传入互斥锁变量的地址		
		4.唤醒接口：唤醒PCB等待队列当中的执行流进行出队
			int pthread_cond_signal(pthread_cond_t* cond)
				唤醒至少一个PCB等待队列当中的线程				
			int pthread_cond_broadcast(pthread_cond_t* cond)
				唤醒所有PCB等待队列当中的线程(抢占式执行)			
		5.销毁：释放动态初始化的条件变量所占用的内存
			int pthread_cond_destroy(pthread_cond_t* cond);
代码：
画一个图：生产者与消费者一人一次		
完整的解释程序：
	消费者(线程A)成功加锁后两种情况：
		1.g_val==1，则执行g_val--，并解锁、给生产者等待队列发送信号
		2.g_val==0，则进入等待队列，释放锁资源，等待生产者发送信号
	生产者是相反的逻辑。

这里有几个问题关于：pthraed_cond_wait(&cond,&lock);
	1.为什么需要传入互斥锁？(互斥)
		简要说：同步只保证了各个执行流对临界资源访问的合理性，而并没有保证对临界资源的互斥属性，因此需要和互斥锁进行配合，完成各个执行流对临界资源访问的同步和互斥属性。
		内部流程：先把调用接口的线程入PCB等待队列，再解锁互斥锁。让生产线程去访问，然后在收到信号唤醒时，出队，继续加锁并访问临界资源。这个函数内部封装了解锁和加锁的操作
	2.为什么先入队，再释放锁资源？(防止通知空队列)
		画个图：相互通知对方的队列
		 如果先释放锁资源再入队可能造成的问题：消费者加锁，当g_val==0时消费者调用wait接口释放锁，还没等消费者入队。这时生产者已经拿到锁资源并执行g_val++并发送信号了，但这时队列是空队。
		 然后消费者入队，生产者再次拿到锁(因为只有它一个)，判断g_val==1因此又释放锁并入队，造成消费生产都卡死。
	3.该接口的内部实现逻辑是什么样的？(做3件事)
		1)将调用pthread_cond_wait的执行流放入PCB等待队列
		2)解互斥锁
		3)等待被唤醒
	4.唤醒之后，会做哪些事？(做两件事)
		1)从PCB队列中移除出来
		2)抢占互斥锁资源
			1_拿到互斥锁，pthread_cond_wait函数返回，接着执行下面的代码
			2_没拿到，阻塞在pthread_cond_wait函数内部抢锁的逻辑当中
				1.一直抢直到时间片耗尽，这个执行流就被切换，程序计数器中就保存抢锁指令，上下文数据当中保存的就是寄存器中的0(还没抢到锁默认给0)。
				2.当再次拿到时间片，从程序计数器和上下文信息当中恢复抢锁的逻辑，继续去抢锁。

总结：
	1.从PCB等待队列当中唤醒的线程，需要循环去判断当前资源数量是否可用(这样判断是程序员自己定义的)
	2.对于不同角色的执行流，应该使用不同的条件变量，在调用wait接口时被放到不同的PCB等待队列中去
总结：对于厨子和顾客，是依次按顺序，一个来一次就切换。
	  对于厨子内部，一旦面碗空了，会抢占式执行
	  对于顾客内部，也是一样的，一旦面碗满了，抢占式执行

生产者和消费者模型
	123规则：1个场景(队列)+两种角色(消费者与生产者)+3种关系(消费者与消费者互斥+生产者与生产互斥+消费者和生产者同步加互斥)
	生产者与消费者模型的优点：
		可以解耦合：生产者只负责生产，消费者只负责消费，生产者和消费者都是通过队列进行交互
		支持忙闲不均：队列起到了缓冲作用(男生追女生带苹果)
		支持并发：消费者只关心队列中是否有数据可以进行消费，生产者只关心队列中是否有空闲的节点进行生产
	如何实现生产者与消费者模型
		1.队列，借助STL中的queue，队列属性：先进先出，所有满足先进先出特性的数据结构都可称为队列。
		2.线程安全的队列
			std::queue 为了效率，并不是一个线程安全的
			互斥：使用互斥锁
			同步：使用条件变量
		3.两种角色的线程
			生产者线程：负责往队列插入数据
			消费者线程：负责从队列里取数据

		push：生产者 pop：消费者
		队列指针要在线程退出之后，释放堆空间
		现象：消费者先于生产者打印一条，原因：已经生产后，将打印时，时间片耗尽，被切换
		只保证了插入和取出的顺序，但不能保证打印顺序

posix信号量
	1.posix信号量可以完成什么任务？
		可以完成进程间和线程间的同步与互斥
	2.本质：信号量=资源计数器(效果等同我们的那个while，判断资源是否可用)+ PCB等待队列(生产者、消费者和lock队列) + 给用户提供的等待和唤醒接口
		对比条件变量，多一个资源计数器，这个资源计数器用来对临界资源进行计数。信号量通过判断自身的资源计数器，来进行条件判断，判断当前资源是否可用。
			可用：则进行资源访问
			不可用：则进行阻塞等待，直到被唤醒
	3.操作接口：
		1)定义：（semaphore：信号量）
			sem_t sem；定义了一个posix信号量
		2)初始化：
			sem_init(sem_t* sem,int pshared,int value)
				sem：传入信号量地址
				pshared：表示当前信号量是用在进程间还是线程间
					 0：线程间使用  
					!0：进程间使用
					ipcs中第三个就是信号量：本质：在共享内存中创建的一块，因此可以进程间通信
					进程间：当使用sem_init初始化信号量为进程间时，会在内核中创建一块共享内存，来保存信号量的数据结构。其中资源计数器，PCB等待队列都是在共享内存当中维护的。
							所以我们调用唤醒或者等待接口的时候，就通过操作共享内存实现了不同进程之间的通信，进而实现不同进程之间的同步与互斥。
					线程间：定义一个全局变量则都能访问到，因为同一块虚拟地址空间
				value：用于初始化信号量当中资源计数器，表示实际的资源的数量
		3)等待：wait接口用于请求“加锁”，加锁则计数器--
			sem_wait(sem_t* sem)-->阻塞等待
			sem_trywait(sem_t* sem)-->非阻塞等待
			sem_timedwait(sem_t* sem,const struct timespec* timeval)-->带有超时时间的等待
			注意：1.调用接口之后，如果资源计数器的值>0则成功获取信号量，如果资源计数器<=0则阻塞该线程
				  2.调用等待接口进行获取信号量，不论是否获取成功，都会对资源计数器-1
		4)唤醒：post接口用于“解锁”，并唤醒队列，解锁则计数器++
			int sem_post(sem_t* sem);发布信号量，表示资源使用完成了，即：归还资源或者生产者重新生产了一个资源，对信号量中的资源计数器+1，并且唤醒PCB等待队列当中的PCB。
			简而言之：归还或者生产了一个，每发布一个信号：资源计数器进行+1，wait接口里面-1
		5)销毁：
			sem_destroy(sem_t* sem)；释放信号量开辟的内存
	4.如何保证同步和互斥，画个图：信号量实现互斥和同步的原理图
		同步：
			1)初始化的时候，根据资源的容量来进行初始化posix信号量当中的资源计数器
		互斥：
			2)初始化时，必须初始化信号量中资源计数器的值为1，表示同一时刻只能有一个访问lock信号量

		互斥：线程A先获取信号量，然后信号量的资源计数器-1。多个获取资源计数器会一直进行-1，但只要计数器小于0则都被阻塞，绝对值就是当前等待获取信号量的线程数。
		同步：线程B访问完成之后，则释放资源：1.调用sem_post(sem_t*)资源计数器+1  
							                 2.通知通知PCB等待队列，线程C访问临界资源
			  若有多个资源计数器(例如为2)，则可实现多个线程同时访问临界资源。
	
	5.用posix实现生产消费模型
		1.线程安全的队列(数组+先进先出的特性)
			用PosWrite=(POSWrite+1)%capacity 计算位置，循环读写
		2.安全队列，什么叫做安全队列？
			同步和互斥：执行流程
				写：sem_init(&ProSem_,0, 1.数组元素个数)；初始化资源计数器和数组容量相同，代表可以多次生产(给小女朋友带多个苹果)
					sem_wait(&ProSem_)； 2.生产者计数器--，如果计数器>0，则继续往下，否则入队等待
					sem_wait(&lock_)；	 3.lock计数器--，锁一般只能有一个访问，若<0则入队等待
					arr[PosWrite] = 10； 4.访问临界资源
					sem_post(&lock_)；	 5."解锁"，计数器++，通知lock等待队列
					sem_post(&ConSem_)； 6.消费者计数器++，通知消费者队列
				读：sem_init(&ConSem_,0,0)；1.初始化消费者计数器为0，代表当前没有资源可以使用。等生产者调用post会使这里的计数器++。
					sem_wait(&ConSem_)；	2.消费者计数器--，如果计数器>0，则继续往下，否则入队等待
					sem_wait(&lock_)；		3.lock
					arr[PosRead_]；			4.访问
					sem_post(&lock_)；		5."解锁"，计数器++，通知lock等待队列
					sem_post(&ProSem_)；	6.生产者计数器++，通知消费者队列


semaphore:信号量

读写锁：和互斥锁很相似，但是比互斥锁高效
	1.适用场景：
		少量写+大量读		
		特点是：允许不同读的线程，在同一时刻获取读模式下的读写锁
		只有写可能造成程序二义性
	2.读写锁的三种状态
		读模式的加锁状态
		写模式的加锁状态
		不加锁的状态
	3.加锁规则
		互斥属性：1.同一时刻只能一个线程可以占有写模式的读写锁---不能同时写
				  2.一个执行流写时，其它线程既不能写也不能读
		并行：1.多个线程可以同时占有读模式的读写锁，在读写锁的内部有一个引用计数，(写时拷贝好像也有引用计数)
			引用计数：表示当前有多少以读模式打开读写锁的线程
				每当打开一个以读模式的读写锁时，引用计数器进行++
				每当释放一个以读模式的读写锁时，引用计数器进行--
		作用：判断释放读模式打开的读写锁，是否能完全解锁
			  如果引用计数减为0，则以读模式的读写锁就解锁了
			  >0：和想要以写模式打开的线程互斥
	4.解锁规则：
		三种模式都可以用解锁接口进行解锁
	5.操作接口
		定义：pthread_rwlock_t
		初始化：pthread_rwlock_init(pthread_rwlock_t*，pthread_rwlockattr_t*);
		加锁：
			pthread_rwlock_rdlock(pthread_rwlock_t*)-->以读模式打开(加锁)
			pthread_rwlock_wrlock(pthread_rwlock_t*)-->以写模式打开(加锁)
		解锁：pthread_rwlock_unlock(pthread_rwlock_t*)
		销毁：pthread_rwlock_destroy(pthread_rwlock_t*)

	总结：读可并行，写不可并行(读打开了，写也不能打开)

	面试题：线程A 读模式打开 加锁成功
			线程B 读模式打开 加锁成功
			线程C 写模式打开 加锁失败
			线程D 读模式打开 加锁？？
	答：线程D应该是加锁失败，因为C是以写加锁，并且被阻塞，因此只有线程C使用完成其他的才能访问。
	机制：保证以写模式打开的线程，一定在某时刻能拿到锁资源

线程池：
	一种线程使用模式，一个程序中线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。
	特点：
		1.线程池维护了多个线程，避免数据某时刻从网络中来到时，短时间创建和销毁线程带来的代价。
		2.线程池不仅能够保证内核的充分利用，还能防止过分调度。
		3.可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络sockets等的数量。
	应用场景：
		1.需要大量线程完成任务，且完成任务的时间比较短
		2.对性能要求苛刻，例如要求服务器能迅速响应客户请求
		3.接受突发性的大量请求，但不至于使服务器因此产生大量线程的应用。例如：天猫双11
	从网络来的数据，直接调用push插入线程池队列，然后在处理完成之后，再发送回，发送队列，之后发送线程，回到网络通过了一个队列(也可以叫缓冲)，把前台和后端解耦开来
		画个图：网络和后端，通过接收线程插入到队列中，处理完成之后通过发送线程发送到网络
	线程池 = 线程安全的队列 + 一大堆的线程(消费线程)
	画个线程池的图：

	线程池中的线程，都是同一种角色的线程，也就是每个线程都执行同样的入口函数。
	例：void* Thread_Start(void*)
	如果线程池中的线程都是执行同样一个入口函数的话，执行的功能是不是就比较单一了？如何满足大量的业务需求呢？
	上面问题简化也就是：如何让相同入口函数的线程，处理不同的请求？
		1.switch case：遇到不同数据，case不同方法，处理大量不同需求时，比较麻烦
		2.数据函数都抛入：向线程池抛入数据的时候，将处理该数据的函数地址和数据一起抛入，线程池当中的线程，只需要调用传入的函数去进行处理数据即可。
			线程安全队列当中的元素：数据 + 处理函数的地址 handler_

总结：线程池 = 线程安全队列 + 一大堆的线程
	  线程安全队列：元素 = 数据 + 处理数据的函数地址

元素类型：
	1.函数指针定义：void* (*Handler_t)(int);返回值为void* 参数为int
		不能少了*，*代表一个函数指针，定义时可以直接Handler_t handler;这里handler就是函数指针
	2.线程的入口函数一定要static修饰的，因为线程入口函数规定参数只能是，只有一个参数void* arg

	采用的方式：将从队列当中拿数据和处理业务的数据解耦开来
		加锁的时候：只需保证拿数据的时候是互斥的
		处理业务数据的时候，多个线程可以并行的去运行

运行结果：可以看到数据的输出并不是1~50顺序输出，这是因为并行式运行

线程池如何退出就变成了一个棘手的问题
	直接退出：如果线程池当中线程安全的队列当中还有数据，也就意味着有数据没有处理。对于客户端而言拿不到请求的答应包，是不能容忍的
	怎么退出：需要判断队列没有数据之后，再进行退出
如何让线程池中的线程优雅的退出？
	背景：担心线程直接退出，导致线程池当中线程安全队列里面还有数据没有处理：
	线程池当中的线程可能存在的几种状态：
		1.加互斥锁
		2.调用pthread_cond_wait当中
		2.在队列当中获取数据
		3.正在处理队列里面的数据
		结论：只有当线程判断了
设置线程退出的流程：
	1.判断队列中没有元素了
	2.IsExit的值为true
	3.要在插入数据之前也判断退出标志位是否为真，因为一旦线程退出，在进行插入就无法处理了
	4.退出之前要通知PCB等待队列，因为其他三种情况都可以通过循环执行到退出，而PCB等待队列中的是阻塞状态因此必须有人通知。
		简而言之：防止都退出了，没有线程通知阻塞的线程
	5.在设置标志位为true的函数中，调用boardcast通知PCB等待队列中被阻塞的线程，把所有等待的线程都通知出来，然后进入抢锁逻辑，没抢到锁的继续等待抢锁，而不会进入等待队列。
	6.设置一个cur_thread标志当前还有多少线程，如果没有就不调用boardcast接口了


为了实现同步因此队列的长度是定长的

设计模式：
	大佬将变成编程经验剥离出来，针对一些常见的问题或者场景，给出一种解决方案，设计成为一种套路。
	优点：
		代码复用程度高，
		可靠度比较高，并且容易理解
		代码框架比较稳定
	分类：
		创建型模式 --> 单例模式：程序全局中只提供一个实例
		结构型模式 --> 适配器模式
		行为型模式 --> 观察者模式

单例模式：(简而言之：一个实例)
	1.特点：全局提供唯一一个类的实例，具有全局变量的特点
	2.使用场景：内存池，数据池
	3.基础的要点：
		全局只有一个实例-->static + 禁止构造 + 禁止拷贝构造 + 禁止赋值拷贝
		线程安全
		调用者是通过类的函数来获取实例
	4.具体的实现
		饿汉模式
			每次吃饭就洗掉碗，后面在吃饭时就直接拿来用
			程序启动的时候进行初始化，资源在程序初始化的时候就全部加载完毕了
				优点：程序运行速度很快，流畅
				缺点：程序初始化的时候耗时比较长
		懒汉模式
			每次吃完饭都不洗碗，第二次吃饭的时候才进行洗碗
			资源在使用的时候才进行实例化，单例类的对象在使用的时候才进行实例化
				优点：程序初始化的时候比较快
				缺点：运行的时候没有恶汉模式流畅
					运行的时候才实例化，可能引起线程安全问题
1.代码双重if，不同线程不用等待获取锁资源，遇到p!=NULL直接return，提高效率
2.需要用volatile对p进行修饰，防止编译器过度优化(直接取寄存器中的值)

CAS无锁编程
	compare and swap
CAS涉及三个操作数：
	需要读写的内存值V
	进行比较的值A
	拟写入的新值B

*/
//所有的代码：
//arg：
//1.临时变量造成的越界访问，问题有两个 1.越界  2.二义性(多次运行的结果不同)
//2.堆上开辟的空间，不会有越界，可以看到抢占式执行，注意在线程退出的地方释放资源
//exit
//1.主线程退出之后僵尸
//2.cancel退出之后又打印了一次
//g_val
//1.一张票卖多次，二义性
//2.一张票一个黄牛(所有正确都执行)
//3.4黄牛只剩3个黄牛，并且程序卡住。原因：解锁位置错误，最后一张票拿出时，一个拿到票且拿到互斥锁的线程break退出，其它的线程一直被卡在加锁位置，拿不到互斥锁，因此阻塞。
//4.第100张票卖出之后，就卡了。原因：自己拿到之后未解锁就去循环，自己卡住了自己，死锁！！
//lock
//1.环锁,执行流A和执行流B都卡在加锁的位置。
//2.吃面和做面保证了互斥，但没有保证同步(也就是可能吃了很多面，吃到了负数去)
//3.吃面和做面一个个顺序执行，逻辑正确，但有多个顾客或者多个厨子，逻辑就错误了。
//cond
//1.两个顾客两个厨子，吃和做了很多面。原因：没有保证大方向上同步，执行流B在第二次抢到锁资源之后，没有关注碗里有没有面
//2.循环判断g_val，程序运行一截子之后被卡住。根本原因：生产者和消费者用了同一个等待队列，也就是可能消费者PCB唤醒了消费者PCB，造成卡死。
//		细说：1.碗里没面，顾客1和2先抢到锁资源然后入队等待 2.厨子1抢到锁然后做了一碗面，然后给队列发送信号只唤醒了一个顾客1，假设这时又是两个厨子抢到锁，然后被入队 3.顾客1吃完面，发送一个信号，出队的却是顾客2，因此永远无法做这一碗面，4个人都被卡在了wait接口里面。
//3.顾客和厨子各一个队列。(完整代码)
//		其实这个代码已经保证了顾客队列和生产者队列也保持同步访问，且每一次的顺序都是一模一样。
//4.用pthread_cond_broadcast(&cond);也可以实现大方向上同步，但是在内部是抢占式执行。因此用两个队列不仅实现了内部同步，而且更能提高效率(broadcast让所有都出队，所有资源抢占式执行)
//pANDc
//C++生产消费
//posix
//sem_t信号量模拟生产消费
//thread_pool
//1.先封装队列元素的类型，即类ThreadTask(数据data_ + 函数指针handler_)，析构什么都不做
//2.定义线程池
/*
	1.成员变量:
		1.队列（元素类型是ThreadTask*） 
		2.队列的容量：capacity_，用于判断队列中的数据
		3.保证安全(互斥锁 + 条件变量(消费者))，这里只有消费者条件变量，因为客户端的请求行为我们是无法控制的，所以就不需要通知生产者进行生产，当生产
		4.初始化时线程数量：thread_capacity_
		5.线程标识符：tid_[]
	2.push(ThreadTask* tt);这里要插入队列，参数类型是我们自定义的ThreadTask
	3.pop(ThreadTask**);这里的出参是二级指针，删除之后应该返回，所删的数据
	4.创建线程：这个是类私有的,且通过arg给线程入口函数传入this指针(需要强转且传进去的是ThreadTask)
	5.线程函数入口函数：static修饰的函数，这是因为线程入口函数规定只能是参数和返回值都void*。先进行pop返回，再调用返回的函数指针和数据，进行处理
	问题：为什么要pop之后返回函数地址，才进行处理函数？
	原因：如果处理数据的代码运行时间很长，那么其他等待解锁的线程会一直等待上一个数据处理完成才进行，这样做处理数据的各个不同就无法并行的运行。
	放在外面处理是为了将数据处理和获取数据的操作解耦开来。
*/
/*
为什么生产了两个0？
因为int data=0；是入口函数中的，即在每一个生产线程都有，并不是临界资源，因此所有data值都有两个
互斥和同步是在push和pop操作内的，出了push和pop就不原子性了，因此可能先消费再生产
在线oj项目，如果保活的机制，可以借用nginx实现，主要研究upstream
*/
#include <iostream>
using namespace std;
class A
{
public:
	A()
		:_a(new int(1))
	{}
	~A()
	{
		delete _a;
		//_a = nullptr;
	}
	void test()
	{
		delete this;
	}
	int* _a;
};
void Test(A*& p)
{
	p->~A();
}
int main()
{
	A* p = new A;
	*(p->_a) = 2;
	printf("%p\n", p);
	p->test();
	*(p->_a) = 3;
	printf("%p", p);
	Test(p);
	printf("%p", p);
	return 0;
}

/*
为啥需要虚拟地址空间？
	1.将空间连续化处理
	2.保护物理内存，防止野指针或者越界指针修改内存，页表映射会检测

页表：
	1.页表中保存了虚拟地址和对应物理地址
	2.页表中保存了read和write权限

delete this:
	1.如果对象是在栈上开辟的空间，则delete this崩溃
	2.如果对象是在堆上开辟的空间
		1.成员变量是堆上开辟的
			会先调用类的析构函数，因此释放了成员变量资源，再次使用时崩溃
		2.成员变量是栈上开辟的
			不会崩溃，对象的空间没有被释放，并且还可以继续操作开辟的空间			
		
*/